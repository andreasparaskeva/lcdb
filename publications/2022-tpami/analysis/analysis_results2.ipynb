{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e548b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['n'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d30f0478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "\n",
    "def get_num_par(model_id):\n",
    "    if model_id == 'last1':\n",
    "        return 1\n",
    "    if model_id in ['pow2', 'log2', 'exp2', 'lin2', 'ilog2']:\n",
    "        return 2\n",
    "    if model_id in ['pow3', 'exp3', 'vap3', 'expp3', 'expd3', 'logpower3']:\n",
    "        return 3\n",
    "    if model_id in ['mmf4', 'wbl4', 'exp4', 'pow4']:\n",
    "        return 4\n",
    "\n",
    "def get_fun_model_id(beta,model_id):\n",
    "    num_par = get_num_par(model_id)\n",
    "    fun = None\n",
    "\n",
    "    # unpack parameters\n",
    "    if num_par == 1:\n",
    "        a = beta[0]\n",
    "    if num_par == 2:\n",
    "        a, b = beta[0], beta[1]\n",
    "    if num_par == 3:\n",
    "        a, b, c = beta[0], beta[1], beta[2]\n",
    "    if num_par == 4:\n",
    "        a, b, c, d = beta[0], beta[1], beta[2], beta[3]\n",
    "\n",
    "    # define curve models\n",
    "    if model_id == 'pow2':\n",
    "        fun = lambda x: -a * x ** (-b)\n",
    "    if model_id == 'pow3':\n",
    "        fun = lambda x: a - b * x ** (-c)\n",
    "    if model_id == 'log2':\n",
    "        fun = lambda x: -a * np.log(x) + b\n",
    "    if model_id == 'exp3':\n",
    "        fun = lambda x: a * np.exp(-b * x) + c\n",
    "    if model_id == 'exp2':\n",
    "        fun = lambda x: a * np.exp(-b * x)\n",
    "    if model_id == 'lin2':\n",
    "        fun = lambda x: a * x + b\n",
    "    if model_id == 'vap3':\n",
    "        fun = lambda x: np.exp(a + b / x + c * np.log(x))\n",
    "    if model_id == 'mmf4':\n",
    "        fun = lambda x: (a * b + c * x ** d) / (b + x ** d)\n",
    "    if model_id == 'wbl4':\n",
    "        fun = lambda x: (c - b * np.exp(-a * (x ** d)))\n",
    "    if model_id == 'exp4':\n",
    "        fun = lambda x: c - np.exp(-a * (x ** d) + b)\n",
    "    if model_id == 'expp3':\n",
    "        # fun = lambda x: a * np.exp(-b*x) + c\n",
    "        fun = lambda x: c - np.exp((x - b) ** a)\n",
    "    if model_id == 'pow4':\n",
    "        fun = lambda x: a - b * (x + d) ** (-c)  # has to closely match pow3\n",
    "    if model_id == 'ilog2':\n",
    "        fun = lambda x: b - (a / np.log(x))\n",
    "    if model_id == 'expd3':\n",
    "        fun = lambda x: c - (c - a) * np.exp(-b * x)\n",
    "    if model_id == 'logpower3':\n",
    "        fun = lambda x: a / (1 + (x / np.exp(b)) ** c)\n",
    "    if model_id == 'last1':\n",
    "        fun = lambda x: (a + x) - x  # casts the prediction to have the correct size\n",
    "    return fun\n",
    "\n",
    "def df_compute_metrics_mean_curve(df,df_info):\n",
    "    pbar = tqdm(total=len(df))\n",
    "    rows_metrics = []\n",
    "    for i in range(0,len(df)):\n",
    "        row = df.iloc[i,:]\n",
    "        anchor_prediction, score = get_info_mean_curve(df_info, row.openmlid, row.learner)\n",
    "        rows_metrics.append(metrics_per_row(row,score,anchor_prediction))\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    df_metrics = pd.DataFrame(rows_metrics,columns=['MSE trn','MSE tst','MSE tst last','L1 trn','L1 tst','L1 tst last','max anchor seen','percentage','n','curve_model'])\n",
    "    return df_metrics\n",
    "\n",
    "def get_info_mean_curve(df_info, openmlid, learner):\n",
    "    q = df_info.query('openmlid==@openmlid and learner==@learner')\n",
    "    q = q.iloc[0,:]\n",
    "    return [q.anchor_prediction, q.score]\n",
    "\n",
    "def metrics_per_row(row, score, anchor_prediction):\n",
    "    \n",
    "    max_anchor_seen = row.max_anchor_seen\n",
    "    prediction = row.prediction\n",
    "    max_anchor = np.max(anchor_prediction)\n",
    "    percentage_train = np.round(max_anchor_seen/max_anchor*100)/100\n",
    "\n",
    "    trn_ind = np.argwhere(max_anchor_seen == anchor_prediction)[0][0] # recover offset\n",
    "    trn_indices = range(0,(trn_ind+1))\n",
    "    tst_indices = range(trn_ind+1,len(anchor_prediction))\n",
    "    n_trn = len(trn_indices)\n",
    "    \n",
    "    y_trn_hat = prediction[trn_indices]\n",
    "    y_trn = score[trn_indices]\n",
    "    y_tst_hat = prediction[tst_indices]\n",
    "    y_tst = score[tst_indices]\n",
    "\n",
    "    MSE_trn = np.mean((y_trn - y_trn_hat)**2)\n",
    "    MSE_tst = np.mean((y_tst - y_tst_hat)**2)\n",
    "    MSE_tst_last = (y_tst[-1] -  y_tst_hat[-1])**2\n",
    "    L1_trn = np.mean((y_trn -y_trn_hat)**2)\n",
    "    L1_tst = np.mean((y_tst - y_tst_hat)**2)\n",
    "    L1_tst_last = (y_tst[-1] - y_tst_hat[-1])**2\n",
    "    \n",
    "    return [MSE_trn,MSE_tst,MSE_tst_last,L1_trn,L1_tst,L1_tst_last,max_anchor_seen,percentage_train,n_trn,row.curve_model]\n",
    "\n",
    "def get_anchors_and_scores_mean_curve(df):\n",
    "    rows = []\n",
    "    for openmlid, df_dataset in tqdm(df.groupby(\"openmlid\")):\n",
    "        for learner, df_learner in df_dataset.groupby(\"learner\"):\n",
    "            sizes = None\n",
    "            scores = []\n",
    "            for (inner, outer), df_seeded in df_learner.groupby([\"inner_seed\", \"outer_seed\"]):\n",
    "                sizes_seed, scores_seed = df_seeded[\"size_train\"].values, df_seeded[\"score_valid\"].values\n",
    "                if sizes is None:\n",
    "                    sizes = sizes_seed\n",
    "                scores.append(scores_seed)\n",
    "            scores = np.array(scores)\n",
    "            if len(scores.shape) != 2:\n",
    "                print(f\"Skipping {learner}\")\n",
    "                continue\n",
    "            mean_scores = np.mean(scores, axis=0)\n",
    "            rows.append([openmlid, learner, sizes, mean_scores])\n",
    "    return pd.DataFrame(rows, columns=[\"openmlid\", \"learner\", \"anchor_prediction\", \"score\"])\n",
    "\n",
    "def get_info_mean_curve(df_info, openmlid, learner):\n",
    "    q = df_info.query('openmlid==@openmlid and learner==@learner')\n",
    "    q = q.iloc[0,:]\n",
    "    return [q.anchor_prediction, q.score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f484496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Hassan Ismail Fawaz <hassan.ismail-fawaz@uha.fr>\n",
    "#         Germain Forestier <germain.forestier@uha.fr>\n",
    "#         Jonathan Weber <jonathan.weber@uha.fr>\n",
    "#         Lhassane Idoumghar <lhassane.idoumghar@uha.fr>\n",
    "#         Pierre-Alain Muller <pierre-alain.muller@uha.fr>\n",
    "# License: GPL3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "#matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = 'Arial'\n",
    "\n",
    "import operator\n",
    "import math\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.stats import friedmanchisquare\n",
    "import networkx\n",
    "\n",
    "def determine_plotting(p_values,average_ranks):\n",
    "\n",
    "    methods = []\n",
    "    for p in p_values:\n",
    "        if p[3] == False:\n",
    "            methods.append(p[0])\n",
    "            methods.append(p[1])\n",
    "    methods = np.unique(np.array(methods))\n",
    "\n",
    "    visible = []\n",
    "    for m in methods:\n",
    "        visible.append(average_ranks[m])\n",
    "\n",
    "    visible = np.array(visible)\n",
    "    if len(visible) == 0:\n",
    "        lowv = None\n",
    "        highv = None\n",
    "        dontplot = []\n",
    "        return lowv, highv, dontplot\n",
    "    lowv = np.floor(np.min(visible))\n",
    "    highv = np.ceil(np.max(visible))\n",
    "\n",
    "    dontplot = []\n",
    "    for method in average_ranks.keys():\n",
    "        rank = average_ranks[method]\n",
    "        if rank > highv:\n",
    "            dontplot.append(method)\n",
    "        if rank < lowv:\n",
    "            dontplot.append(method)\n",
    "\n",
    "    return int(lowv), int(highv), dontplot\n",
    "\n",
    "# inspired from orange3 https://docs.orange.biolab.si/3/data-mining-library/reference/evaluation.cd.html\n",
    "def graph_ranks(avranks, names, p_values, cd=None, cdmethod=None, lowv=5, highv=15,\n",
    "                width=100, textspace=1, reverse=True, filename=None, labels=False, dpi=10, dontplot=[],**kwargs):\n",
    "    \"\"\"\n",
    "    Draws a CD graph, which is used to display  the differences in methods'\n",
    "    performance. See Janez Demsar, Statistical Comparisons of Classifiers over\n",
    "    Multiple Data Sets, 7(Jan):1--30, 2006.\n",
    "\n",
    "    Needs matplotlib to work.\n",
    "\n",
    "    The image is ploted on `plt` imported using\n",
    "    `import matplotlib.pyplot as plt`.\n",
    "\n",
    "    Args:\n",
    "        avranks (list of float): average ranks of methods.\n",
    "        names (list of str): names of methods.\n",
    "        cd (float): Critical difference used for statistically significance of\n",
    "            difference between methods.\n",
    "        cdmethod (int, optional): the method that is compared with other methods\n",
    "            If omitted, show pairwise comparison of methods\n",
    "        lowv (int, optional): the lowest shown rank\n",
    "        highv (int, optional): the highest shown rank\n",
    "        width (int, optional): default width in inches (default: 6)\n",
    "        textspace (int, optional): space on figure sides (in inches) for the\n",
    "            method names (default: 1)\n",
    "        reverse (bool, optional):  if set to `True`, the lowest rank is on the\n",
    "            right (default: `False`)\n",
    "        filename (str, optional): output file name (with extension). If not\n",
    "            given, the function does not write a file.\n",
    "        labels (bool, optional): if set to `True`, the calculated avg rank\n",
    "        values will be displayed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "        from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Function graph_ranks requires matplotlib.\")\n",
    "\n",
    "    width = float(width)\n",
    "    textspace = float(textspace)\n",
    "\n",
    "    def nth(l, n):\n",
    "        \"\"\"\n",
    "        Returns only nth elemnt in a list.\n",
    "        \"\"\"\n",
    "        n = lloc(l, n)\n",
    "        return [a[n] for a in l]\n",
    "\n",
    "    def lloc(l, n):\n",
    "        \"\"\"\n",
    "        List location in list of list structure.\n",
    "        Enable the use of negative locations:\n",
    "        -1 is the last element, -2 second last...\n",
    "        \"\"\"\n",
    "        if n < 0:\n",
    "            return len(l[0]) + n\n",
    "        else:\n",
    "            return n\n",
    "\n",
    "    def mxrange(lr):\n",
    "        \"\"\"\n",
    "        Multiple xranges. Can be used to traverse matrices.\n",
    "        This function is very slow due to unknown number of\n",
    "        parameters.\n",
    "\n",
    "        >>> mxrange([3,5])\n",
    "        [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2)]\n",
    "\n",
    "        >>> mxrange([[3,5,1],[9,0,-3]])\n",
    "        [(3, 9), (3, 6), (3, 3), (4, 9), (4, 6), (4, 3)]\n",
    "\n",
    "        \"\"\"\n",
    "        if not len(lr):\n",
    "            yield ()\n",
    "        else:\n",
    "            # it can work with single numbers\n",
    "            index = lr[0]\n",
    "            if isinstance(index, int):\n",
    "                index = [index]\n",
    "            for a in range(*index):\n",
    "                for b in mxrange(lr[1:]):\n",
    "                    yield tuple([a] + list(b))\n",
    "\n",
    "    def print_figure(fig, *args, **kwargs):\n",
    "        canvas = FigureCanvasAgg(fig)\n",
    "        canvas.print_figure(*args, **kwargs)\n",
    "\n",
    "    sums = avranks\n",
    "\n",
    "    nnames = names\n",
    "    ssums = sums\n",
    "\n",
    "    if lowv is None:\n",
    "        lowv = min(1, int(math.floor(min(ssums))))\n",
    "    if highv is None:\n",
    "        highv = max(len(avranks), int(math.ceil(max(ssums))))\n",
    "\n",
    "    cline = 0.4\n",
    "\n",
    "    k = len(sums)\n",
    "\n",
    "    lines = None\n",
    "\n",
    "    linesblank = 0\n",
    "    scalewidth = width - 2 * textspace\n",
    "\n",
    "    def rankpos(rank):\n",
    "        if not reverse:\n",
    "            a = rank - lowv\n",
    "        else:\n",
    "            a = highv - rank\n",
    "        return textspace + scalewidth / (highv - lowv) * a\n",
    "\n",
    "    distanceh = 0.25\n",
    "\n",
    "    cline += distanceh\n",
    "\n",
    "    # calculate height needed height of an image\n",
    "    minnotsignificant = max(2 * 0.2, linesblank)\n",
    "    height = cline + ((k + 1) / 2) * 0.2 + minnotsignificant\n",
    "\n",
    "    fig = plt.figure(figsize=(width, height),dpi=dpi)\n",
    "    fig.set_facecolor('white')\n",
    "    ax = fig.add_axes([0, 0, 1, 1])  # reverse y axis\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    hf = 1. / height  # height factor\n",
    "    wf = 1. / width\n",
    "\n",
    "    def hfl(l):\n",
    "        return [a * hf for a in l]\n",
    "\n",
    "    def wfl(l):\n",
    "        return [a * wf for a in l]\n",
    "\n",
    "    # Upper left corner is (0,0).\n",
    "    ax.plot([0, 1], [0, 1], c=\"w\")\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(1, 0)\n",
    "\n",
    "    def line(l, color='k', **kwargs):\n",
    "        \"\"\"\n",
    "        Input is a list of pairs of points.\n",
    "        \"\"\"\n",
    "        ax.plot(wfl(nth(l, 0)), hfl(nth(l, 1)), color=color, **kwargs)\n",
    "\n",
    "    def text(x, y, s, *args, **kwargs):\n",
    "        ax.text(wf * x, hf * y, s, *args, **kwargs)\n",
    "\n",
    "    line([(textspace, cline), (width - textspace, cline)], linewidth=2)\n",
    "\n",
    "    bigtick = 0.3\n",
    "    smalltick = 0.15\n",
    "    linewidth = 0.5\n",
    "    linewidth_sign = 2.0\n",
    "\n",
    "    tick = None\n",
    "    for a in list(np.arange(lowv, highv, 0.5)) + [highv]:\n",
    "        tick = smalltick\n",
    "        if a == int(a):\n",
    "            tick = bigtick\n",
    "        line([(rankpos(a), cline - tick / 2),\n",
    "              (rankpos(a), cline)],\n",
    "             linewidth=2)\n",
    "\n",
    "    for a in range(lowv, highv + 1):\n",
    "        text(rankpos(a), cline - tick / 2 - 0.05, str(a),\n",
    "             ha=\"center\", va=\"bottom\", size=16)\n",
    "\n",
    "    k = len(ssums)\n",
    "\n",
    "    def filter_names(name):\n",
    "        return name\n",
    "\n",
    "    space_between_names = 0.24\n",
    "\n",
    "    for i in range(math.ceil(k / 2)):\n",
    "        current_name = filter_names(nnames[i])\n",
    "        chei = cline + minnotsignificant + i * space_between_names\n",
    "        if not current_name in dontplot:\n",
    "            line([(rankpos(ssums[i]), cline),\n",
    "                  (rankpos(ssums[i]), chei),\n",
    "                  (textspace - 0.1, chei)],\n",
    "                 linewidth=linewidth)\n",
    "        if labels:\n",
    "            text(textspace + 0.3, chei - 0.075, format(ssums[i], '.2f'), ha=\"right\", va=\"center\", size=10)\n",
    "        text(textspace - 0.2, chei, filter_names(nnames[i]), ha=\"right\", va=\"center\", size=16)\n",
    "\n",
    "    for i in range(math.ceil(k / 2), k):\n",
    "        current_name = filter_names(nnames[i])\n",
    "        chei = cline + minnotsignificant + (k - i - 1) * space_between_names\n",
    "        if not current_name in dontplot:\n",
    "            line([(rankpos(ssums[i]), cline),\n",
    "                  (rankpos(ssums[i]), chei),\n",
    "                  (textspace + scalewidth + 0.1, chei)],\n",
    "                 linewidth=linewidth)\n",
    "        if labels:\n",
    "            text(textspace + scalewidth - 0.3, chei - 0.075, format(ssums[i], '.2f'), ha=\"left\", va=\"center\", size=10)\n",
    "        text(textspace + scalewidth + 0.2, chei, filter_names(nnames[i]),\n",
    "             ha=\"left\", va=\"center\", size=16)\n",
    "\n",
    "    # no-significance lines\n",
    "    def draw_lines(lines, side=0.05, height=0.1):\n",
    "        start = cline + 0.2\n",
    "\n",
    "        for l, r in lines:\n",
    "            line([(rankpos(ssums[l]) - side, start),\n",
    "                  (rankpos(ssums[r]) + side, start)],\n",
    "                 linewidth=linewidth_sign)\n",
    "            start += height\n",
    "            print('drawing: ', l, r)\n",
    "\n",
    "    # draw_lines(lines)\n",
    "    start = cline + 0.2\n",
    "    side = 0\n",
    "    height = 0.1\n",
    "\n",
    "    # draw no significant lines\n",
    "    # get the cliques\n",
    "    cliques = form_cliques(p_values, nnames)\n",
    "    i = 1\n",
    "    achieved_half = False\n",
    "    #print(nnames)\n",
    "    for clq in cliques:\n",
    "        if len(clq) == 1:\n",
    "            continue\n",
    "        #print(clq)\n",
    "        min_idx = np.array(clq).min()\n",
    "        max_idx = np.array(clq).max()\n",
    "        if min_idx >= len(nnames) / 2 and achieved_half == False:\n",
    "            start = cline + 0.25\n",
    "            achieved_half = True\n",
    "        line([(rankpos(ssums[min_idx]) - side, start),\n",
    "              (rankpos(ssums[max_idx]) + side, start)],\n",
    "             linewidth=linewidth_sign,color='r')\n",
    "        start += height\n",
    "\n",
    "\n",
    "def form_cliques(p_values, nnames):\n",
    "    \"\"\"\n",
    "    This method forms the cliques\n",
    "    \"\"\"\n",
    "    # first form the numpy matrix data\n",
    "    m = len(nnames)\n",
    "    g_data = np.zeros((m, m), dtype=np.int64)\n",
    "    for p in p_values:\n",
    "        if p[3] == False:\n",
    "            i = np.where(nnames == p[0])[0][0]\n",
    "            j = np.where(nnames == p[1])[0][0]\n",
    "            min_i = min(i, j)\n",
    "            max_j = max(i, j)\n",
    "            g_data[min_i, max_j] = 1\n",
    "\n",
    "    g = networkx.Graph(g_data)\n",
    "    return networkx.find_cliques(g)\n",
    "\n",
    "\n",
    "def draw_cd_diagram(df_perf=None, alpha=0.05, title=None, labels=False):\n",
    "    \"\"\"\n",
    "    Draws the critical difference diagram given the list of pairwise classifiers that are\n",
    "    significant or not\n",
    "    \"\"\"\n",
    "    p_values, average_ranks, _ = wilcoxon_holm(df_perf=df_perf, alpha=alpha)\n",
    "\n",
    "    print(average_ranks)\n",
    "\n",
    "    for p in p_values:\n",
    "        print(p)\n",
    "\n",
    "\n",
    "    graph_ranks(average_ranks.values, average_ranks.keys(), p_values,\n",
    "                cd=None, reverse=True, width=30, textspace=3, labels=labels)\n",
    "\n",
    "    font = {'family': 'sans-serif',\n",
    "        'color':  'black',\n",
    "        'weight': 'normal',\n",
    "        'size': 22,\n",
    "        }\n",
    "    if title:\n",
    "        plt.title(title,fontdict=font, y=0.9, x=0.5)\n",
    "    plt.savefig('cd-diagram.pdf',bbox_inches='tight')\n",
    "\n",
    "def wilcoxon_holm(alpha=0.05, df_perf=None):\n",
    "    \"\"\"\n",
    "    Applies the wilcoxon signed rank test between each pair of algorithm and then use Holm\n",
    "    to reject the null's hypothesis\n",
    "    \"\"\"\n",
    "    #print(pd.unique(df_perf['classifier_name']))\n",
    "    # count the number of tested datasets per classifier\n",
    "    df_counts = pd.DataFrame({'count': df_perf.groupby(\n",
    "        ['classifier_name']).size()}).reset_index()\n",
    "    # get the maximum number of tested datasets\n",
    "    max_nb_datasets = df_counts['count'].max()\n",
    "    # get the list of classifiers who have been tested on nb_max_datasets\n",
    "    classifiers = list(df_counts.loc[df_counts['count'] == max_nb_datasets]\n",
    "                       ['classifier_name'])\n",
    "    # test the null hypothesis using friedman before doing a post-hoc analysis\n",
    "    friedman_p_value = friedmanchisquare(*(\n",
    "        np.array(df_perf.loc[df_perf['classifier_name'] == c]['accuracy'])\n",
    "        for c in classifiers))[1]\n",
    "    if friedman_p_value >= alpha:\n",
    "        # then the null hypothesis over the entire classifiers cannot be rejected\n",
    "        print('the null hypothesis over the entire classifiers cannot be rejected')\n",
    "        exit()\n",
    "    # get the number of classifiers\n",
    "    m = len(classifiers)\n",
    "    # init array that contains the p-values calculated by the Wilcoxon signed rank test\n",
    "    p_values = []\n",
    "    # loop through the algorithms to compare pairwise\n",
    "    for i in range(m - 1):\n",
    "        # get the name of classifier one\n",
    "        classifier_1 = classifiers[i]\n",
    "        # get the performance of classifier one\n",
    "        perf_1 = np.array(df_perf.loc[df_perf['classifier_name'] == classifier_1]['accuracy']\n",
    "                          , dtype=np.float64)\n",
    "        for j in range(i + 1, m):\n",
    "            # get the name of the second classifier\n",
    "            classifier_2 = classifiers[j]\n",
    "            # get the performance of classifier one\n",
    "            perf_2 = np.array(df_perf.loc[df_perf['classifier_name'] == classifier_2]\n",
    "                              ['accuracy'], dtype=np.float64)\n",
    "            # calculate the p_value\n",
    "            p_value = wilcoxon(perf_1, perf_2, zero_method='pratt')[1]\n",
    "            # appen to the list\n",
    "            p_values.append((classifier_1, classifier_2, p_value, False))\n",
    "    # get the number of hypothesis\n",
    "    k = len(p_values)\n",
    "    # sort the list in acsending manner of p-value\n",
    "    p_values.sort(key=operator.itemgetter(2))\n",
    "\n",
    "    # loop through the hypothesis\n",
    "    for i in range(k):\n",
    "        # correct alpha with holm\n",
    "        new_alpha = float(alpha / (k - i))\n",
    "        # test if significant after holm's correction of alpha\n",
    "        if p_values[i][2] <= new_alpha:\n",
    "            p_values[i] = (p_values[i][0], p_values[i][1], p_values[i][2], True)\n",
    "        else:\n",
    "            # stop\n",
    "            break\n",
    "    # compute the average ranks to be returned (useful for drawing the cd diagram)\n",
    "    # sort the dataframe of performances\n",
    "    sorted_df_perf = df_perf.loc[df_perf['classifier_name'].isin(classifiers)]. \\\n",
    "        sort_values(['classifier_name', 'dataset_name'])\n",
    "    # get the rank data\n",
    "    rank_data = np.array(sorted_df_perf['accuracy']).reshape(m, max_nb_datasets)\n",
    "\n",
    "    # create the data frame containg the accuracies\n",
    "    df_ranks = pd.DataFrame(data=rank_data, index=np.sort(classifiers), columns=\n",
    "    np.unique(sorted_df_perf['dataset_name']))\n",
    "\n",
    "    # number of wins\n",
    "    dfff = df_ranks.rank(ascending=False)\n",
    "    #print(dfff[dfff == 1.0].sum(axis=1))\n",
    "\n",
    "    # average the ranks\n",
    "    average_ranks = df_ranks.rank(ascending=False).mean(axis=1).sort_values(ascending=False)\n",
    "    # return the p-values and the average ranks\n",
    "    return p_values, average_ranks, max_nb_datasets\n",
    "\n",
    "#df_perf = pd.read_csv('DefaultvsTunedvsEnsembleCritDiffAcc.csv',index_col=False)\n",
    "\n",
    "#draw_cd_diagram(df_perf=df_perf, title='Accuracy', labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4333f480",
   "metadata": {},
   "source": [
    "# Cleaning the data and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea132d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "df = pd.read_csv('lcdb_new.csv')\n",
    "if exists('lcdb_new_anchors_scores.p'):\n",
    "    df_anchors_and_scores = pd.read_pickle('lcdb_new_anchors_scores.p')\n",
    "else:\n",
    "    df_anchors_and_scores = get_anchors_and_scores_mean_curve(df)\n",
    "    df_anchors_and_scores.to_pickle('lcdb_new_anchors_scores.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ba60181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_list = []\n",
    "df_extrapolations_list = []\n",
    "for i in range(0,10):\n",
    "    df_metrics_list.append(pd.read_pickle('metrics%d.p' % i))\n",
    "    df_extrapolations_list.append(pd.read_pickle('extrapolations%d.p' % i))\n",
    "    \n",
    "df_metrics = pd.concat(df_metrics_list,axis=0)\n",
    "df_extrapolations = pd.concat(df_extrapolations_list,axis=0)\n",
    "assert(len(df_metrics) == len(df_extrapolations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ffa06e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE trn</th>\n",
       "      <th>MSE tst</th>\n",
       "      <th>MSE tst last</th>\n",
       "      <th>L1 trn</th>\n",
       "      <th>L1 tst</th>\n",
       "      <th>L1 tst last</th>\n",
       "      <th>max anchor seen</th>\n",
       "      <th>percentage</th>\n",
       "      <th>n</th>\n",
       "      <th>curve_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.883226e-08</td>\n",
       "      <td>0.009280</td>\n",
       "      <td>0.030293</td>\n",
       "      <td>2.883226e-08</td>\n",
       "      <td>0.009280</td>\n",
       "      <td>0.030293</td>\n",
       "      <td>45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>pow4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.987909e-07</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>9.987909e-07</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>pow4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.207896e-07</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>8.207896e-07</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>pow4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.857116e-06</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>1.857116e-06</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>128</td>\n",
       "      <td>0.02</td>\n",
       "      <td>7</td>\n",
       "      <td>pow4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.766385e-06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.766385e-06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>181</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8</td>\n",
       "      <td>pow4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78075</th>\n",
       "      <td>4.650329e-05</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>4.650329e-05</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.14</td>\n",
       "      <td>19</td>\n",
       "      <td>logpower3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78076</th>\n",
       "      <td>4.831424e-05</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>4.831424e-05</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>11585</td>\n",
       "      <td>0.20</td>\n",
       "      <td>20</td>\n",
       "      <td>logpower3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78077</th>\n",
       "      <td>4.986637e-05</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>4.986637e-05</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.28</td>\n",
       "      <td>21</td>\n",
       "      <td>logpower3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78078</th>\n",
       "      <td>4.926202e-05</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>4.926202e-05</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>23170</td>\n",
       "      <td>0.40</td>\n",
       "      <td>22</td>\n",
       "      <td>logpower3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78079</th>\n",
       "      <td>4.891286e-05</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>4.891286e-05</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.57</td>\n",
       "      <td>23</td>\n",
       "      <td>logpower3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>758864 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            MSE trn   MSE tst  MSE tst last        L1 trn    L1 tst  \\\n",
       "0      2.883226e-08  0.009280      0.030293  2.883226e-08  0.009280   \n",
       "1      9.987909e-07  0.000413      0.000628  9.987909e-07  0.000413   \n",
       "2      8.207896e-07  0.000451      0.000634  8.207896e-07  0.000451   \n",
       "3      1.857116e-06  0.000071      0.000084  1.857116e-06  0.000071   \n",
       "4      1.766385e-06  0.000015      0.000006  1.766385e-06  0.000015   \n",
       "...             ...       ...           ...           ...       ...   \n",
       "78075  4.650329e-05  0.000149      0.000167  4.650329e-05  0.000149   \n",
       "78076  4.831424e-05  0.000099      0.000096  4.831424e-05  0.000099   \n",
       "78077  4.986637e-05  0.000056      0.000051  4.986637e-05  0.000056   \n",
       "78078  4.926202e-05  0.000041      0.000030  4.926202e-05  0.000041   \n",
       "78079  4.891286e-05  0.000016      0.000016  4.891286e-05  0.000016   \n",
       "\n",
       "       L1 tst last  max anchor seen  percentage   n curve_model  \n",
       "0         0.030293               45        0.01   4        pow4  \n",
       "1         0.000628               64        0.01   5        pow4  \n",
       "2         0.000634               91        0.01   6        pow4  \n",
       "3         0.000084              128        0.02   7        pow4  \n",
       "4         0.000006              181        0.03   8        pow4  \n",
       "...            ...              ...         ...  ..         ...  \n",
       "78075     0.000167             8192        0.14  19   logpower3  \n",
       "78076     0.000096            11585        0.20  20   logpower3  \n",
       "78077     0.000051            16384        0.28  21   logpower3  \n",
       "78078     0.000030            23170        0.40  22   logpower3  \n",
       "78079     0.000016            32768        0.57  23   logpower3  \n",
       "\n",
       "[758864 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c60df1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>openmlid</th>\n",
       "      <th>learner</th>\n",
       "      <th>max_anchor_seen</th>\n",
       "      <th>prediction</th>\n",
       "      <th>curve_model</th>\n",
       "      <th>beta</th>\n",
       "      <th>fails_init</th>\n",
       "      <th>fails_fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>45</td>\n",
       "      <td>[0.8882253060512815, 0.9129123443101395, 0.932...</td>\n",
       "      <td>pow4</td>\n",
       "      <td>[3.4418299555164094, 2.6634082053587433, 0.018...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>64</td>\n",
       "      <td>[0.8880107342619459, 0.9132911872218537, 0.933...</td>\n",
       "      <td>pow4</td>\n",
       "      <td>[0.9749338390233945, 19434.87738296287, 3.0299...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>91</td>\n",
       "      <td>[0.8880402887090619, 0.9132249469590998, 0.933...</td>\n",
       "      <td>pow4</td>\n",
       "      <td>[0.9748273144231531, 41404.69654147434, 3.1754...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>128</td>\n",
       "      <td>[0.8879204803603522, 0.9137250177077135, 0.932...</td>\n",
       "      <td>pow4</td>\n",
       "      <td>[0.9910112534284682, 3.4028442598555797, 1.106...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>181</td>\n",
       "      <td>[0.8878519374777576, 0.9139775632395017, 0.932...</td>\n",
       "      <td>pow4</td>\n",
       "      <td>[0.9982729629370699, 1.286412335833199, 0.8414...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78075</th>\n",
       "      <td>40668</td>\n",
       "      <td>sklearn.tree.ExtraTreeClassifier</td>\n",
       "      <td>8192</td>\n",
       "      <td>[0.5222589272226801, 0.5291752066764958, 0.535...</td>\n",
       "      <td>logpower3</td>\n",
       "      <td>[111.87466275358531, 149.9942324352611, -0.036...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78076</th>\n",
       "      <td>40668</td>\n",
       "      <td>sklearn.tree.ExtraTreeClassifier</td>\n",
       "      <td>11585</td>\n",
       "      <td>[0.521376958849426, 0.5284236038385511, 0.5349...</td>\n",
       "      <td>logpower3</td>\n",
       "      <td>[127.36760447759718, 150.68239991663455, -0.03...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78077</th>\n",
       "      <td>40668</td>\n",
       "      <td>sklearn.tree.ExtraTreeClassifier</td>\n",
       "      <td>16384</td>\n",
       "      <td>[0.5205428218287173, 0.5277046723702262, 0.534...</td>\n",
       "      <td>logpower3</td>\n",
       "      <td>[139.85412544281138, 150.6689381729169, -0.037...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78078</th>\n",
       "      <td>40668</td>\n",
       "      <td>sklearn.tree.ExtraTreeClassifier</td>\n",
       "      <td>23170</td>\n",
       "      <td>[0.5200052330792921, 0.5272367680674765, 0.533...</td>\n",
       "      <td>logpower3</td>\n",
       "      <td>[137.23693674088128, 148.624058705217, -0.0382...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78079</th>\n",
       "      <td>40668</td>\n",
       "      <td>sklearn.tree.ExtraTreeClassifier</td>\n",
       "      <td>32768</td>\n",
       "      <td>[0.5194606085837714, 0.5267586099061149, 0.533...</td>\n",
       "      <td>logpower3</td>\n",
       "      <td>[150.85954742312038, 149.69436811252245, -0.03...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>758864 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       openmlid                           learner  max_anchor_seen  \\\n",
       "0            24                        SVC_linear               45   \n",
       "1            24                        SVC_linear               64   \n",
       "2            24                        SVC_linear               91   \n",
       "3            24                        SVC_linear              128   \n",
       "4            24                        SVC_linear              181   \n",
       "...         ...                               ...              ...   \n",
       "78075     40668  sklearn.tree.ExtraTreeClassifier             8192   \n",
       "78076     40668  sklearn.tree.ExtraTreeClassifier            11585   \n",
       "78077     40668  sklearn.tree.ExtraTreeClassifier            16384   \n",
       "78078     40668  sklearn.tree.ExtraTreeClassifier            23170   \n",
       "78079     40668  sklearn.tree.ExtraTreeClassifier            32768   \n",
       "\n",
       "                                              prediction curve_model  \\\n",
       "0      [0.8882253060512815, 0.9129123443101395, 0.932...        pow4   \n",
       "1      [0.8880107342619459, 0.9132911872218537, 0.933...        pow4   \n",
       "2      [0.8880402887090619, 0.9132249469590998, 0.933...        pow4   \n",
       "3      [0.8879204803603522, 0.9137250177077135, 0.932...        pow4   \n",
       "4      [0.8878519374777576, 0.9139775632395017, 0.932...        pow4   \n",
       "...                                                  ...         ...   \n",
       "78075  [0.5222589272226801, 0.5291752066764958, 0.535...   logpower3   \n",
       "78076  [0.521376958849426, 0.5284236038385511, 0.5349...   logpower3   \n",
       "78077  [0.5205428218287173, 0.5277046723702262, 0.534...   logpower3   \n",
       "78078  [0.5200052330792921, 0.5272367680674765, 0.533...   logpower3   \n",
       "78079  [0.5194606085837714, 0.5267586099061149, 0.533...   logpower3   \n",
       "\n",
       "                                                    beta  fails_init  \\\n",
       "0      [3.4418299555164094, 2.6634082053587433, 0.018...           0   \n",
       "1      [0.9749338390233945, 19434.87738296287, 3.0299...           0   \n",
       "2      [0.9748273144231531, 41404.69654147434, 3.1754...           0   \n",
       "3      [0.9910112534284682, 3.4028442598555797, 1.106...           0   \n",
       "4      [0.9982729629370699, 1.286412335833199, 0.8414...           0   \n",
       "...                                                  ...         ...   \n",
       "78075  [111.87466275358531, 149.9942324352611, -0.036...           0   \n",
       "78076  [127.36760447759718, 150.68239991663455, -0.03...           0   \n",
       "78077  [139.85412544281138, 150.6689381729169, -0.037...           0   \n",
       "78078  [137.23693674088128, 148.624058705217, -0.0382...           0   \n",
       "78079  [150.85954742312038, 149.69436811252245, -0.03...           0   \n",
       "\n",
       "       fails_fit  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "78075          0  \n",
       "78076          0  \n",
       "78077          0  \n",
       "78078          0  \n",
       "78079          0  \n",
       "\n",
       "[758864 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extrapolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6118e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extrapolations_no_curve_model = df_extrapolations.loc[:, df_extrapolations.columns != 'curve_model']\n",
    "df_total = pd.concat([df_extrapolations_no_curve_model,df_metrics],axis=1)\n",
    "df_total = df_total.rename(columns={'MSE trn':'MSE_trn','MSE tst':'MSE_tst','MSE tst last': 'MSE_tst_last', 'L1 trn':'L1_trn', 'L1 tst':'L1_tst', 'L1 tst last':'L1_tst_last'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "634ee8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>openmlid</th>\n",
       "      <th>learner</th>\n",
       "      <th>max_anchor_seen</th>\n",
       "      <th>prediction</th>\n",
       "      <th>beta</th>\n",
       "      <th>fails_init</th>\n",
       "      <th>fails_fit</th>\n",
       "      <th>MSE_trn</th>\n",
       "      <th>MSE_tst</th>\n",
       "      <th>MSE_tst_last</th>\n",
       "      <th>L1_trn</th>\n",
       "      <th>L1_tst</th>\n",
       "      <th>L1_tst_last</th>\n",
       "      <th>max anchor seen</th>\n",
       "      <th>percentage</th>\n",
       "      <th>n</th>\n",
       "      <th>curve_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>45</td>\n",
       "      <td>[0.8882253060512815, 0.9129123443101395, 0.932...</td>\n",
       "      <td>[3.4418299555164094, 2.6634082053587433, 0.018...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.883226e-08</td>\n",
       "      <td>0.009280</td>\n",
       "      <td>0.030293</td>\n",
       "      <td>2.883226e-08</td>\n",
       "      <td>0.009280</td>\n",
       "      <td>0.030293</td>\n",
       "      <td>45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>pow4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>64</td>\n",
       "      <td>[0.8880107342619459, 0.9132911872218537, 0.933...</td>\n",
       "      <td>[0.9749338390233945, 19434.87738296287, 3.0299...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.987909e-07</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>9.987909e-07</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>pow4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>91</td>\n",
       "      <td>[0.8880402887090619, 0.9132249469590998, 0.933...</td>\n",
       "      <td>[0.9748273144231531, 41404.69654147434, 3.1754...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.207896e-07</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>8.207896e-07</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6</td>\n",
       "      <td>pow4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>128</td>\n",
       "      <td>[0.8879204803603522, 0.9137250177077135, 0.932...</td>\n",
       "      <td>[0.9910112534284682, 3.4028442598555797, 1.106...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.857116e-06</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>1.857116e-06</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>128</td>\n",
       "      <td>0.02</td>\n",
       "      <td>7</td>\n",
       "      <td>pow4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>SVC_linear</td>\n",
       "      <td>181</td>\n",
       "      <td>[0.8878519374777576, 0.9139775632395017, 0.932...</td>\n",
       "      <td>[0.9982729629370699, 1.286412335833199, 0.8414...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.766385e-06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.766385e-06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>181</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8</td>\n",
       "      <td>pow4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78075</th>\n",
       "      <td>40668</td>\n",
       "      <td>sklearn.tree.ExtraTreeClassifier</td>\n",
       "      <td>8192</td>\n",
       "      <td>[0.5222589272226801, 0.5291752066764958, 0.535...</td>\n",
       "      <td>[111.87466275358531, 149.9942324352611, -0.036...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.650329e-05</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>4.650329e-05</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.14</td>\n",
       "      <td>19</td>\n",
       "      <td>logpower3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78076</th>\n",
       "      <td>40668</td>\n",
       "      <td>sklearn.tree.ExtraTreeClassifier</td>\n",
       "      <td>11585</td>\n",
       "      <td>[0.521376958849426, 0.5284236038385511, 0.5349...</td>\n",
       "      <td>[127.36760447759718, 150.68239991663455, -0.03...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.831424e-05</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>4.831424e-05</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>11585</td>\n",
       "      <td>0.20</td>\n",
       "      <td>20</td>\n",
       "      <td>logpower3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78077</th>\n",
       "      <td>40668</td>\n",
       "      <td>sklearn.tree.ExtraTreeClassifier</td>\n",
       "      <td>16384</td>\n",
       "      <td>[0.5205428218287173, 0.5277046723702262, 0.534...</td>\n",
       "      <td>[139.85412544281138, 150.6689381729169, -0.037...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.986637e-05</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>4.986637e-05</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.28</td>\n",
       "      <td>21</td>\n",
       "      <td>logpower3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78078</th>\n",
       "      <td>40668</td>\n",
       "      <td>sklearn.tree.ExtraTreeClassifier</td>\n",
       "      <td>23170</td>\n",
       "      <td>[0.5200052330792921, 0.5272367680674765, 0.533...</td>\n",
       "      <td>[137.23693674088128, 148.624058705217, -0.0382...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.926202e-05</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>4.926202e-05</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>23170</td>\n",
       "      <td>0.40</td>\n",
       "      <td>22</td>\n",
       "      <td>logpower3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78079</th>\n",
       "      <td>40668</td>\n",
       "      <td>sklearn.tree.ExtraTreeClassifier</td>\n",
       "      <td>32768</td>\n",
       "      <td>[0.5194606085837714, 0.5267586099061149, 0.533...</td>\n",
       "      <td>[150.85954742312038, 149.69436811252245, -0.03...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.891286e-05</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>4.891286e-05</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.57</td>\n",
       "      <td>23</td>\n",
       "      <td>logpower3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>758864 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       openmlid                           learner  max_anchor_seen  \\\n",
       "0            24                        SVC_linear               45   \n",
       "1            24                        SVC_linear               64   \n",
       "2            24                        SVC_linear               91   \n",
       "3            24                        SVC_linear              128   \n",
       "4            24                        SVC_linear              181   \n",
       "...         ...                               ...              ...   \n",
       "78075     40668  sklearn.tree.ExtraTreeClassifier             8192   \n",
       "78076     40668  sklearn.tree.ExtraTreeClassifier            11585   \n",
       "78077     40668  sklearn.tree.ExtraTreeClassifier            16384   \n",
       "78078     40668  sklearn.tree.ExtraTreeClassifier            23170   \n",
       "78079     40668  sklearn.tree.ExtraTreeClassifier            32768   \n",
       "\n",
       "                                              prediction  \\\n",
       "0      [0.8882253060512815, 0.9129123443101395, 0.932...   \n",
       "1      [0.8880107342619459, 0.9132911872218537, 0.933...   \n",
       "2      [0.8880402887090619, 0.9132249469590998, 0.933...   \n",
       "3      [0.8879204803603522, 0.9137250177077135, 0.932...   \n",
       "4      [0.8878519374777576, 0.9139775632395017, 0.932...   \n",
       "...                                                  ...   \n",
       "78075  [0.5222589272226801, 0.5291752066764958, 0.535...   \n",
       "78076  [0.521376958849426, 0.5284236038385511, 0.5349...   \n",
       "78077  [0.5205428218287173, 0.5277046723702262, 0.534...   \n",
       "78078  [0.5200052330792921, 0.5272367680674765, 0.533...   \n",
       "78079  [0.5194606085837714, 0.5267586099061149, 0.533...   \n",
       "\n",
       "                                                    beta  fails_init  \\\n",
       "0      [3.4418299555164094, 2.6634082053587433, 0.018...           0   \n",
       "1      [0.9749338390233945, 19434.87738296287, 3.0299...           0   \n",
       "2      [0.9748273144231531, 41404.69654147434, 3.1754...           0   \n",
       "3      [0.9910112534284682, 3.4028442598555797, 1.106...           0   \n",
       "4      [0.9982729629370699, 1.286412335833199, 0.8414...           0   \n",
       "...                                                  ...         ...   \n",
       "78075  [111.87466275358531, 149.9942324352611, -0.036...           0   \n",
       "78076  [127.36760447759718, 150.68239991663455, -0.03...           0   \n",
       "78077  [139.85412544281138, 150.6689381729169, -0.037...           0   \n",
       "78078  [137.23693674088128, 148.624058705217, -0.0382...           0   \n",
       "78079  [150.85954742312038, 149.69436811252245, -0.03...           0   \n",
       "\n",
       "       fails_fit       MSE_trn   MSE_tst  MSE_tst_last        L1_trn  \\\n",
       "0              0  2.883226e-08  0.009280      0.030293  2.883226e-08   \n",
       "1              0  9.987909e-07  0.000413      0.000628  9.987909e-07   \n",
       "2              0  8.207896e-07  0.000451      0.000634  8.207896e-07   \n",
       "3              0  1.857116e-06  0.000071      0.000084  1.857116e-06   \n",
       "4              0  1.766385e-06  0.000015      0.000006  1.766385e-06   \n",
       "...          ...           ...       ...           ...           ...   \n",
       "78075          0  4.650329e-05  0.000149      0.000167  4.650329e-05   \n",
       "78076          0  4.831424e-05  0.000099      0.000096  4.831424e-05   \n",
       "78077          0  4.986637e-05  0.000056      0.000051  4.986637e-05   \n",
       "78078          0  4.926202e-05  0.000041      0.000030  4.926202e-05   \n",
       "78079          0  4.891286e-05  0.000016      0.000016  4.891286e-05   \n",
       "\n",
       "         L1_tst  L1_tst_last  max anchor seen  percentage   n curve_model  \n",
       "0      0.009280     0.030293               45        0.01   4        pow4  \n",
       "1      0.000413     0.000628               64        0.01   5        pow4  \n",
       "2      0.000451     0.000634               91        0.01   6        pow4  \n",
       "3      0.000071     0.000084              128        0.02   7        pow4  \n",
       "4      0.000015     0.000006              181        0.03   8        pow4  \n",
       "...         ...          ...              ...         ...  ..         ...  \n",
       "78075  0.000149     0.000167             8192        0.14  19   logpower3  \n",
       "78076  0.000099     0.000096            11585        0.20  20   logpower3  \n",
       "78077  0.000056     0.000051            16384        0.28  21   logpower3  \n",
       "78078  0.000041     0.000030            23170        0.40  22   logpower3  \n",
       "78079  0.000016     0.000016            32768        0.57  23   logpower3  \n",
       "\n",
       "[758864 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d8da62",
   "metadata": {},
   "source": [
    "# Remove fits that failed repeatedly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b3aa144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fail due to init 0\n",
      "fail due to fit 298\n",
      "fail total 298\n"
     ]
    }
   ],
   "source": [
    "def remove_fails(df_total):\n",
    "\n",
    "    fail_init = df_total['fails_init'] > 1000\n",
    "    fail_fit = df_total['fails_fit'] > 100\n",
    "\n",
    "    print('fail due to init %d' % fail_init.sum())\n",
    "    print('fail due to fit %d' % fail_fit.sum())\n",
    "\n",
    "    fail_ind = pd.concat([fail_init,fail_fit],axis=1)\n",
    "    fail_ind = fail_ind.any(axis=1)\n",
    "    print('fail total %d' % sum(fail_ind))\n",
    "\n",
    "    df_fail = df_total[fail_ind]\n",
    "    df_total_new = df_total[fail_ind == False]\n",
    "    \n",
    "    return [df_total_new,df_fail]\n",
    "\n",
    "[df_total_no_fail,df_fail] = remove_fails(df_total)\n",
    "assert(len(df_total_no_fail) + len(df_fail) == len(df_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f17ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert((df_total_no_fail['fails_fit'] > 100).sum() == 0) # check that indeed we got rid of them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828dbe29",
   "metadata": {},
   "source": [
    "# Remove rows with nan or inf in the numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "454190b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows with nans / infs: 307\n",
      "columns with nans / infs:\n",
      "openmlid           False\n",
      "learner            False\n",
      "max_anchor_seen    False\n",
      "fails_init         False\n",
      "fails_fit          False\n",
      "MSE_trn            False\n",
      "MSE_tst             True\n",
      "MSE_tst_last        True\n",
      "L1_trn             False\n",
      "L1_tst              True\n",
      "L1_tst_last         True\n",
      "max anchor seen    False\n",
      "percentage         False\n",
      "n                  False\n",
      "curve_model        False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "def remove_nan_and_inf(df_total):\n",
    "\n",
    "    numeric = df_total.iloc[:,[0,1,2,5,6,7,8,9,10,11,12,13,14,15,16]]\n",
    "    #numeric.describe()\n",
    "\n",
    "    ind_nan_or_inf = numeric.isin([np.inf, -np.inf, np.nan]).any(axis=1)\n",
    "    print('number of rows with nans / infs:',ind_nan_or_inf.sum())\n",
    "    print('columns with nans / infs:')\n",
    "    print(numeric.isin([np.inf, -np.inf, np.nan]).any())\n",
    "    \n",
    "    return df_total[ind_nan_or_inf == False], df_total[ind_nan_or_inf == True]\n",
    "\n",
    "df_no_fail_no_nan_or_inf, df_nan_or_inf = remove_nan_and_inf(df_total_no_fail)\n",
    "assert(len(df_no_fail_no_nan_or_inf) + len(df_nan_or_inf) == len(df_total_no_fail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8d538a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = df_no_fail_no_nan_or_inf.iloc[:,[0,1,2,5,6,7,8,9,10,11,12,13,14,15,16]]\n",
    "numeric = numeric.isin([np.inf, -np.inf, np.nan]).any(axis=1)\n",
    "assert(numeric.sum() == 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0593277a",
   "metadata": {},
   "source": [
    "# Remove rows whose MSE train / test / test last performance is larger than 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ce3baa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance too bad for analysis:\n",
      "MSE_trn           100\n",
      "MSE_tst         18996\n",
      "MSE_tst_last    24833\n",
      "L1_trn            100\n",
      "L1_tst          18996\n",
      "L1_tst_last     24833\n",
      "dtype: int64\n",
      "number of offending rows:\n",
      "24846\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def remove_performace_too_bad(df_total):\n",
    "    \n",
    "    numeric = df_total.iloc[:,[0,1,2,5,6,7,8,9,10,11,12,13,14,15,16]]\n",
    "\n",
    "    threshold = 100\n",
    "\n",
    "    error_MSE_trn = numeric['MSE_trn'] > threshold\n",
    "    error_MSE_tst = numeric['MSE_tst'] > threshold\n",
    "    error_MSE_tst_last = numeric['MSE_tst_last'] > threshold\n",
    "    error_L1_trn = numeric['L1_trn'] > threshold\n",
    "    error_L1_tst = numeric['L1_tst'] > threshold\n",
    "    error_L1_tst_last = numeric['L1_tst_last'] > threshold\n",
    "\n",
    "    errors_fit = pd.concat([error_MSE_trn,error_MSE_tst,error_MSE_tst_last,error_L1_trn,error_L1_tst,error_L1_tst_last],axis=1)\n",
    "    print('performance too bad for analysis:')\n",
    "    print(errors_fit.sum())\n",
    "    print('number of offending rows:')\n",
    "    print(errors_fit.any(axis=1).sum())\n",
    "\n",
    "    errors_ind = errors_fit.any(axis=1)\n",
    "    return df_total[errors_ind == False], df_total[errors_ind == True]\n",
    "\n",
    "df_no_fail_no_nan_or_inf_no_too_bad, df_too_bad = remove_performace_too_bad(df_no_fail_no_nan_or_inf)\n",
    "assert(len(df_no_fail_no_nan_or_inf_no_too_bad) + len(df_too_bad) == len(df_no_fail_no_nan_or_inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d437f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = df_no_fail_no_nan_or_inf_no_too_bad.iloc[:,[0,1,2,5,6,7,8,9,10,11,12,13,14,15,16]]\n",
    "threshold = 100\n",
    "\n",
    "error_MSE_trn = numeric['MSE_trn'] > threshold\n",
    "error_MSE_tst = numeric['MSE_tst'] > threshold\n",
    "error_MSE_tst_last = numeric['MSE_tst_last'] > threshold\n",
    "error_L1_trn = numeric['L1_trn'] > threshold\n",
    "error_L1_tst = numeric['L1_tst'] > threshold\n",
    "error_L1_tst_last = numeric['L1_tst_last'] > threshold\n",
    "\n",
    "errors_fit = pd.concat([error_MSE_trn,error_MSE_tst,error_MSE_tst_last,error_L1_trn,error_L1_tst,error_L1_tst_last],axis=1)\n",
    "errors_ind = errors_fit.any(axis=1)\n",
    "assert(errors_ind.sum() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2cd6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f914b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan_or_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbd6180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reason = ['fail']*len(df_fail)\n",
    "df_fail2 = df_fail.copy()\n",
    "df_fail2.insert(0, 'reason', reason)\n",
    "reason = ['nan_or_inf'] * len(df_nan_or_inf)\n",
    "df_nan_or_inf2 = df_nan_or_inf.copy()\n",
    "df_nan_or_inf2.insert(0, 'reason', reason)\n",
    "reason = ['too_bad'] * len(df_too_bad)\n",
    "df_too_bad2 = df_too_bad.copy()\n",
    "df_too_bad2.insert(0, 'reason', reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0cb8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94492671",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_removed = pd.concat([df_fail2,df_nan_or_inf2,df_too_bad2],axis=0)\n",
    "df_clean = df_no_fail_no_nan_or_inf_no_too_bad\n",
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9d74d4",
   "metadata": {},
   "source": [
    "# Statistics for failed fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f453015",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series = df_total['fails_fit'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c884a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = my_series.index\n",
    "Y = my_series.values\n",
    "plt.figure()\n",
    "plt.plot(X,Y)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('number of failed fits')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae923c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6d065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for (n, df_temp) in (df_removed.groupby('n')):\n",
    "    X.append(n)\n",
    "    num_total = len(df_total.query('n==%d'%n))\n",
    "    Y.append(len(df_temp)/num_total)\n",
    "plt.figure()\n",
    "plt.plot(X,Y)\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('percentage fits failed')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad90ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_removed['reason'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a00fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_removed['curve_model'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5d685e",
   "metadata": {},
   "source": [
    "# Statistics per curve model and curve model table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for [curve_model, df_removed_curve] in df_removed.groupby('curve_model'):\n",
    "    too_bad = (df_removed_curve['reason'] == 'too_bad').sum()\n",
    "    nan_or_inf = (df_removed_curve['reason'] == 'nan_or_inf').sum()\n",
    "    fail = (df_removed_curve['reason'] == 'fail').sum()\n",
    "    total = len(df_removed_curve)\n",
    "    rows.append([curve_model,fail,nan_or_inf,too_bad,total])\n",
    "failfits = pd.DataFrame(rows,columns=['curve model','fail','nan or inf','too bad','total'])\n",
    "row_total = failfits.iloc[:,[1,2,3,4]].sum()\n",
    "total = list(row_total)\n",
    "rows.append(['all',total[0],total[1],total[2],total[3]])\n",
    "failfits = pd.DataFrame(rows,columns=['curve_model','fail','nan_or_inf','too_bad','total'])\n",
    "failfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2f8533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import latex\n",
    "\n",
    "from sympy.utilities.lambdify import lambdify\n",
    "import sympy as sym\n",
    "\n",
    "def get_fun_sym(model_id):\n",
    "    \n",
    "    x = sym.Symbol('x')\n",
    "    y = sym.Symbol('y')\n",
    "    a = sym.Symbol('a')\n",
    "    b = sym.Symbol('b')\n",
    "    c = sym.Symbol('c')\n",
    "    d = sym.Symbol('d')\n",
    "    \n",
    "    if model_id == 'pow2':\n",
    "        fun = -a * x **(-b)\n",
    "    if model_id == 'pow3':\n",
    "        fun = a - b * x **(-c)\n",
    "    if model_id == 'log2':\n",
    "        fun = -a * sym.log(x) + b\n",
    "    if model_id == 'exp3':\n",
    "        fun = a * sym.exp(-b*x) + c\n",
    "    if model_id == 'exp2':\n",
    "        fun = a * sym.exp(-b*x)\n",
    "    if model_id == 'lin2':\n",
    "        fun = a * x + b\n",
    "    if model_id == 'vap3':\n",
    "        fun = sym.exp(a + b/x + c * sym.log(x))\n",
    "    if model_id == 'mmf4':\n",
    "        fun = (a * b + c * x ** d)/(b + x ** d)\n",
    "    if model_id == 'wbl4':\n",
    "        fun = (c - b * sym.exp(-a*(x**d)))\n",
    "    if model_id == 'exp4':\n",
    "        fun = c - sym.exp(-a*(x**d) + b)\n",
    "    if model_id == 'expp3':\n",
    "        fun = c - sym.exp((x-b)**a)\n",
    "    if model_id == 'pow4':\n",
    "        fun = a - b*(x + d)**(-c)\n",
    "    if model_id == 'ilog2':\n",
    "        fun = b - (a/sym.log(x))\n",
    "    if model_id == 'expd3':\n",
    "        fun = c - (c - a)*sym.exp(-b*x)\n",
    "    if model_id == 'logpower3':\n",
    "        fun = a / (1 + (x / sym.exp(b))**c)\n",
    "    if model_id == 'last1':\n",
    "        fun = a\n",
    "    return fun\n",
    "\n",
    "model_names = ['pow4','pow3', 'pow2', 'log2', 'exp2', 'exp3', 'lin2', 'last1', 'vap3','mmf4','wbl4','exp4','expp3','ilog2','expd3','logpower3']\n",
    "\n",
    "# order curve models by number of parameters\n",
    "par = []\n",
    "for cm in model_names:\n",
    "    par.append([cm,get_num_par(cm)])\n",
    "    \n",
    "df_ordered = pd.DataFrame(par).sort_values(by=1,axis=0)\n",
    "cm_ordered = df_ordered.iloc[:,0].values\n",
    "cm_ordered\n",
    "\n",
    "# references to works that use curve models\n",
    "ref = dict()\n",
    "ref['pow2'] = '\\\\textbf{\\\\cite{Frey1999}*}\\\\cite{Gu2001}\\\\cite{Singh2005}\\\\cite{Last2007}'\n",
    "ref['pow3'] = '\\\\textbf{\\\\cite{Gu2001}*\\\\cite{Kolachina2012}*}\\\\cite{Cortes1994}\\\\cite{Brumen2012}\\\\cite{brumen2021overview}'\n",
    "ref['log2'] = '\\\\textbf{\\\\cite{Singh2005}*}\\\\cite{Frey1999}\\\\cite{Gu2001}\\\\cite{Last2007}\\\\cite{Brumen2012}\\\\cite{brumen2021overview}'\n",
    "ref['exp3'] = '\\\\textbf{\\\\cite{Brumen2012}*}\\\\cite{Kolachina2012}\\\\cite{brumen2021overview}'\n",
    "ref['exp2'] = '\\\\cite{Frey1999}\\\\cite{Singh2005}\\\\cite{Last2007}'\n",
    "ref['lin2'] = '\\\\cite{Frey1999}\\\\cite{Singh2005}\\\\cite{Last2007}\\\\cite{Brumen2012}'\n",
    "ref['vap3'] = '\\\\cite{Gu2001}'\n",
    "ref['mmf4'] = '\\\\cite{Gu2001}'\n",
    "ref['wbl4'] = '\\\\cite{Gu2001}'\n",
    "ref['exp4'] = '\\\\cite{Kolachina2012}'\n",
    "ref['expp3'] = '\\\\cite{Kolachina2012}'\n",
    "ref['pow4'] = '\\\\cite{Kolachina2012}'\n",
    "ref['ilog2'] = '\\\\cite{Kolachina2012}'\n",
    "ref['expd3'] = '\\\\cite{Kolachina2012}'\n",
    "ref['logpower3'] = ''\n",
    "ref['last1'] = ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60339190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import latex\n",
    "\n",
    "print('''\n",
    "\\\\begin{table}[]\n",
    "\\\\ttfamily\n",
    "\\\\begin{tabular}{lllllll}\n",
    "curve model & equation & references & reject & inf or nan & too bad & total\\\\\\\\\n",
    "''',end='')\n",
    "\n",
    "for cm in cm_ordered:\n",
    "    fun = get_fun_sym(cm)\n",
    "    print(cm, end=' & ')\n",
    "    print('$%s$' % latex(fun), end=' & ')\n",
    "    print(ref[cm],end=' & ')\n",
    "    row = failfits.query('curve_model == \"%s\"' % cm)\n",
    "    if len(row) == 0:\n",
    "        print('0 & 0 & 0 & 0 \\\\\\\\\\n',end='')\n",
    "    else:\n",
    "        row=row.iloc[0,:]\n",
    "        print(row.fail, end=' & ')\n",
    "        print(row.nan_or_inf, end=' & ')\n",
    "        print(row.too_bad, end=' & ')\n",
    "        print(row.total, end='\\\\\\\\\\n')\n",
    "\n",
    "print('''\\\\end{tabular}\n",
    "\\\\end{table}\n",
    "''')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de6f48",
   "metadata": {},
   "source": [
    "# Make percentage buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d0884",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_buckets = [1, 0.8, 0.4, 0.2, 0.1, 0.05]\n",
    "percentage_buckets = np.array(percentage_buckets)\n",
    "\n",
    "bucket_list = [np.nan]*(len(df_clean))\n",
    "bucket_list = np.array(bucket_list)\n",
    "\n",
    "for i in range(0,len(percentage_buckets)):\n",
    "    p = percentage_buckets[i]\n",
    "    inbucket = df_clean['percentage'] < p\n",
    "    bucket_list = np.where(inbucket.values, p, bucket_list)\n",
    "\n",
    "df_clean_buckets = df_clean.copy()\n",
    "df_clean_buckets.insert(0,'percentage_bucket',bucket_list)\n",
    "df_clean_buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c28d01",
   "metadata": {},
   "source": [
    "# Statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e41f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_table(df,performance_measure,logscale=False):\n",
    "\n",
    "    curve_models = df['curve_model'].unique()\n",
    "\n",
    "    rows = []\n",
    "    info_rows = []\n",
    "    for (openmlid, df_dataset) in tqdm(df.groupby('openmlid')):\n",
    "        for (learner, df_learner) in df_dataset.groupby('learner'):\n",
    "            for (n, df_n) in df_learner.groupby('n'):\n",
    "                new_row = []\n",
    "                bucket = df_n.iloc[0,:].percentage_bucket\n",
    "                info_rows.append([openmlid,learner,n,bucket])\n",
    "                for curve_model in curve_models:\n",
    "                    row = df_n.query('curve_model == @curve_model')\n",
    "                    score = np.nan\n",
    "                    if len(row) > 0:\n",
    "                        row = row.iloc[0,:]\n",
    "                        score = row[performance_measure]\n",
    "                    new_row.append(score)\n",
    "                rows.append(new_row)\n",
    "\n",
    "    a = np.array(rows)\n",
    "    if logscale == True:\n",
    "        a = np.log(a)\n",
    "    a = pd.DataFrame(a,columns=curve_models)\n",
    "    a_info = np.array(info_rows)\n",
    "    a_info = pd.DataFrame(a_info,columns=['openmlid','learner','n','bucket'])\n",
    "    b = pd.concat([a_info,a],axis=1)\n",
    "    return b\n",
    "\n",
    "def remove_rows_with_nan_or_inf(c):\n",
    "    c = c.copy()\n",
    "    ind_nan_or_inf = c.isin([np.inf, -np.inf, np.nan]).any(axis=1)\n",
    "    c = c[ind_nan_or_inf == False]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c099acfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists('table_MSE_tst_last.p'):\n",
    "    table_MSE_tst_last = pd.read_pickle('table_MSE_tst_last.p')\n",
    "else:\n",
    "    table_MSE_tst_last = convert_table(df_clean_buckets,'MSE_tst_last')\n",
    "    table_MSE_tst_last.to_pickle('table_MSE_tst_last.p')\n",
    "\n",
    "if exists('table_MSE_tst.p'):\n",
    "    table_MSE_tst = pd.read_pickle('table_MSE_tst.p')\n",
    "else:\n",
    "    table_MSE_tst = convert_table(df_clean_buckets,'MSE_tst')\n",
    "    table_MSE_tst.to_pickle('table_MSE_tst.p')\n",
    "\n",
    "if exists('table_MSE_trn.p'):\n",
    "    table_MSE_trn = pd.read_pickle('table_MSE_trn.p')\n",
    "else:\n",
    "    table_MSE_trn = convert_table(df_clean_buckets,'MSE_trn')\n",
    "    table_MSE_trn.to_pickle('table_MSE_trn.p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05866a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n",
    "\n",
    "def prepare_data_for_cd(b):\n",
    "    \n",
    "    c = remove_rows_with_nan_or_inf(b)\n",
    "\n",
    "    melted = pd.melt(c,id_vars=['openmlid','learner','n'],value_vars=curve_models)\n",
    "    dataset_name = melted.agg('{0[openmlid]},{0[learner]},{0[n]}'.format, axis=1)\n",
    "    melted['dataset_name'] = dataset_name\n",
    "\n",
    "    df_cd = melted[['variable','dataset_name','value']]\n",
    "    df_cd = df_cd.rename(columns={'variable': 'classifier_name', 'value': 'accuracy'})\n",
    "    df_cd['accuracy'] = -df_cd['accuracy']\n",
    "    return df_cd\n",
    "\n",
    "def cd_plot(df_cd,lowv=1,highv=16,dontplot=[],title=None,auto=True):\n",
    "    p_values, average_ranks, _ = wilcoxon_holm(df_perf=df_cd, alpha=0.05)\n",
    "    \n",
    "    if auto:\n",
    "        lowv, highv, dontplot = determine_plotting(p_values,average_ranks)\n",
    "    \n",
    "    graph_ranks(average_ranks.values, average_ranks.keys(), p_values,\n",
    "                cd=None, reverse=True, width=8, textspace=0, labels=True, dpi=600,lowv=lowv,highv=highv,dontplot=dontplot)\n",
    "    font = {'family': 'sans-serif',\n",
    "        'color':  'black',\n",
    "        'weight': 'normal',\n",
    "        'size': 22,\n",
    "        }\n",
    "    if title:\n",
    "        plt.title(title,fontdict=font, y=0.9, x=0.5)\n",
    "    return lowv, highv, dontplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a543c8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_MSE_tst_last_all = prepare_data_for_cd(table_MSE_tst_last)\n",
    "table_MSE_tst_all = prepare_data_for_cd(table_MSE_tst)\n",
    "table_MSE_trn_all = prepare_data_for_cd(table_MSE_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814f46fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_MSE_tst_last_005 = prepare_data_for_cd(table_MSE_tst_last.query('bucket==\"0.05\"'))\n",
    "table_MSE_tst_last_010 = prepare_data_for_cd(table_MSE_tst_last.query('bucket==\"0.1\"'))\n",
    "table_MSE_tst_last_020 = prepare_data_for_cd(table_MSE_tst_last.query('bucket==\"0.2\"'))\n",
    "table_MSE_tst_last_040 = prepare_data_for_cd(table_MSE_tst_last.query('bucket==\"0.4\"'))\n",
    "table_MSE_tst_last_080 = prepare_data_for_cd(table_MSE_tst_last.query('bucket==\"0.8\"'))\n",
    "\n",
    "table_MSE_tst_005 = prepare_data_for_cd(table_MSE_tst.query('bucket==\"0.05\"'))\n",
    "table_MSE_tst_010 = prepare_data_for_cd(table_MSE_tst.query('bucket==\"0.1\"'))\n",
    "table_MSE_tst_020 = prepare_data_for_cd(table_MSE_tst.query('bucket==\"0.2\"'))\n",
    "table_MSE_tst_040 = prepare_data_for_cd(table_MSE_tst.query('bucket==\"0.4\"'))\n",
    "table_MSE_tst_080 = prepare_data_for_cd(table_MSE_tst.query('bucket==\"0.8\"'))\n",
    "\n",
    "table_MSE_trn_005 = prepare_data_for_cd(table_MSE_trn.query('bucket==\"0.05\"'))\n",
    "table_MSE_trn_010 = prepare_data_for_cd(table_MSE_trn.query('bucket==\"0.1\"'))\n",
    "table_MSE_trn_020 = prepare_data_for_cd(table_MSE_trn.query('bucket==\"0.2\"'))\n",
    "table_MSE_trn_040 = prepare_data_for_cd(table_MSE_trn.query('bucket==\"0.4\"'))\n",
    "table_MSE_trn_080 = prepare_data_for_cd(table_MSE_trn.query('bucket==\"0.8\"'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79f251e",
   "metadata": {},
   "source": [
    "# MSE test last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc17edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = table_MSE_tst_last['bucket'].unique()\n",
    "print(buckets)\n",
    "\n",
    "n_per_bucket = []\n",
    "bucket_f = []\n",
    "for b in buckets:\n",
    "    bucket_f.append(float(b))\n",
    "    n_per_bucket.append(len(table_MSE_tst_last.query('bucket==@b')))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(bucket_f,n_per_bucket)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e579a560",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "ext = '.png'\n",
    "plots.append((table_MSE_tst_last_all,'ranking MSE test last','MSE_tst_last'+ext))\n",
    "plots.append((table_MSE_tst_last_005,'ranking MSE test last <5%','MSE_tst_last_005'+ext))\n",
    "plots.append((table_MSE_tst_last_010,'ranking MSE test last 5%-10%','MSE_tst_last_010'+ext))\n",
    "plots.append((table_MSE_tst_last_020,'ranking MSE test last 10%-20%','MSE_tst_last_020'+ext))\n",
    "plots.append((table_MSE_tst_last_040,'ranking MSE test last 20%-40%','MSE_tst_last_040'+ext))\n",
    "plots.append((table_MSE_tst_last_080,'ranking MSE test last 40%-80%','MSE_tst_last_080'+ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bbc3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in plots:\n",
    "    table = p[0]\n",
    "    title = p[1]\n",
    "    fn = p[2]\n",
    "\n",
    "    cd_plot(table,title=title)\n",
    "    plt.savefig(fn,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d0fb37",
   "metadata": {},
   "source": [
    "# MSE test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd1e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = table_MSE_tst['bucket'].unique()\n",
    "print(buckets)\n",
    "\n",
    "n_per_bucket = []\n",
    "bucket_f = []\n",
    "for b in buckets:\n",
    "    bucket_f.append(float(b))\n",
    "    n_per_bucket.append(len(table_MSE_tst.query('bucket==@b')))\n",
    "    \n",
    "print(n_per_bucket)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(bucket_f,n_per_bucket)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1634ac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "ext = '.png'\n",
    "plots.append((table_MSE_tst_all,'ranking MSE test ','MSE_tst'+ext))\n",
    "plots.append((table_MSE_tst_005,'ranking MSE test <5%','MSE_tst_005'+ext))\n",
    "plots.append((table_MSE_tst_010,'ranking MSE test 5%-10%','MSE_tst_010'+ext))\n",
    "plots.append((table_MSE_tst_020,'ranking MSE test 10%-20%','MSE_tst_020'+ext))\n",
    "plots.append((table_MSE_tst_040,'ranking MSE test 20%-40%','MSE_tst_040'+ext))\n",
    "plots.append((table_MSE_tst_080,'ranking MSE test 40%-80%','MSE_tst_080'+ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3691f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in plots:\n",
    "    table = p[0]\n",
    "    title = p[1]\n",
    "    fn = p[2]\n",
    "\n",
    "    cd_plot(table,title=title)\n",
    "    plt.savefig(fn,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac47303",
   "metadata": {},
   "source": [
    "# MSE trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522493f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = table_MSE_trn['bucket'].unique()\n",
    "print(buckets)\n",
    "\n",
    "n_per_bucket = []\n",
    "bucket_f = []\n",
    "for b in buckets:\n",
    "    bucket_f.append(float(b))\n",
    "    n_per_bucket.append(len(table_MSE_trn.query('bucket==@b')))\n",
    "    \n",
    "print(n_per_bucket)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(bucket_f,n_per_bucket)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d0e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "ext = '.png'\n",
    "plots.append((table_MSE_trn_all,'ranking MSE train ','MSE_trn'+ext))\n",
    "plots.append((table_MSE_trn_005,'ranking MSE train <5%','MSE_trn_005'+ext))\n",
    "plots.append((table_MSE_trn_010,'ranking MSE train 5%-10%','MSE_trn_010'+ext))\n",
    "plots.append((table_MSE_trn_020,'ranking MSE train 10%-20%','MSE_trn_020'+ext))\n",
    "plots.append((table_MSE_trn_040,'ranking MSE train 20%-40%','MSE_trn_040'+ext))\n",
    "plots.append((table_MSE_trn_080,'ranking MSE train 40%-80%','MSE_trn_080'+ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9fa676",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in plots:\n",
    "    table = p[0]\n",
    "    title = p[1]\n",
    "    fn = p[2]\n",
    "\n",
    "    cd_plot(table,title=title)\n",
    "    plt.savefig(fn,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402483b2",
   "metadata": {},
   "source": [
    "# Visualize a learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d64fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_XY(row):\n",
    "    learner = row.learner\n",
    "    openmlid = row.openmlid\n",
    "    [X, Y] = get_info_mean_curve(df_anchors_and_scores, openmlid, learner)\n",
    "    return [X, Y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86055ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_ylim(row, margin=0.05):\n",
    "    \n",
    "    [X, Y] = get_XY(row)\n",
    "    Y_diff = np.max(Y) - np.min(Y)\n",
    "    plt.ylim([np.min(Y),np.max(Y)])\n",
    "    #plt.ylim([np.min(Y) - Y_diff*margin,np.max(Y) + Y_diff*margin])\n",
    "\n",
    "\n",
    "def plot_data(row):\n",
    "    \n",
    "    [X, Y] = get_XY(row)\n",
    "\n",
    "    plt.plot(X,Y,'*r',label='test data')\n",
    "    set_ylim(row)\n",
    "    plt.xlabel('anchors')\n",
    "    plt.ylabel('accuracy')\n",
    "    \n",
    "    learner = row.learner\n",
    "    openmlid = row.openmlid\n",
    "    plt.title('%s dataset %d' % (learner, openmlid))\n",
    "\n",
    "def plot_trn_data(row):\n",
    "    \n",
    "    [X, Y] = get_XY(row)\n",
    "    \n",
    "    offset = np.argwhere(X == row.max_anchor_seen)[0][0]\n",
    "\n",
    "    X_trn = X[:offset+1]\n",
    "    Y_trn = Y[:offset+1]\n",
    "    \n",
    "    plt.plot(X_trn,Y_trn,'ob',label='train data')\n",
    "    set_ylim(row)\n",
    "    plt.xlabel('anchors')\n",
    "    plt.ylabel('accuracy')\n",
    "    \n",
    "    learner = row.learner\n",
    "    openmlid = row.openmlid\n",
    "    plt.title('%s dataset %d' % (learner, openmlid))\n",
    "\n",
    "def get_curve_models(df,row):\n",
    "    \n",
    "    learner = row.learner\n",
    "    openmlid = row.openmlid\n",
    "    max_anchor_seen = row.max_anchor_seen\n",
    "    \n",
    "    df_models = df_clean.query('learner == \"%s\" and openmlid == @openmlid and max_anchor_seen == @max_anchor_seen' % learner)\n",
    "    \n",
    "    return df_models\n",
    "\n",
    "def get_curve_model(df,row,cm):\n",
    "    \n",
    "    df_models = get_curve_models(df,row)\n",
    "    df_models2 = df_models.query('curve_model == \"%s\"' % cm)\n",
    "    my_row = df_models2.iloc[0,:]\n",
    "    return my_row\n",
    "    \n",
    "def plot_prediction(row):\n",
    "    \n",
    "    curve_model = row.curve_model\n",
    "    [X, Y] = get_XY(row)\n",
    "    \n",
    "    plt.plot(X,row.prediction,':',label=curve_model)\n",
    "    plt.legend()\n",
    "    \n",
    "def plot_prediction_smooth(row):\n",
    "    \n",
    "    curve_model = row.curve_model\n",
    "    \n",
    "    [X, Y] = get_XY(row)\n",
    "    \n",
    "    fun = get_fun_model_id(row.beta,curve_model)\n",
    "    \n",
    "    X_plot = np.arange(np.min(X),np.max(X))\n",
    "    Y_hat = fun(X_plot)\n",
    "    \n",
    "    plt.plot(X_plot,Y_hat,'-',label=curve_model)\n",
    "    plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2427141",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = np.random.randint(0,len(df_clean))\n",
    "#row = df_clean.sample()\n",
    "#row = df_removed.sample()\n",
    "#row = df_no_fail_no_nan_or_inf_no_too_bad.sample()\n",
    "row = df_clean.iloc[num,:]\n",
    "\n",
    "get_curve_model(df,row,cm):\n",
    "\n",
    "\n",
    "print(num)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plot_data(row)\n",
    "plot_trn_data(row)\n",
    "#plot_prediction(row)\n",
    "plot_prediction_smooth(row)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5712935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmf4_curves = df_clean.query('curve_model == \"mmf4\"')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f87cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = mmf4_curves.sort_values(by='MSE_tst',axis=0)\n",
    "\n",
    "row = mmf4_curves.iloc[-10,:]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plot_data(row)\n",
    "plot_trn_data(row)\n",
    "#plot_prediction(row)\n",
    "plot_prediction_smooth(row)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0194dba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b608f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num = 441371\n",
    "num = np.random.randint(0,len(df_clean))\n",
    "\n",
    "#row = df_clean.sample()\n",
    "#row = df_removed.sample()\n",
    "#row = df_no_fail_no_nan_or_inf_no_too_bad.sample()\n",
    "row = df_clean.iloc[num,:]\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plot_data(row)\n",
    "plot_trn_data(row)\n",
    "#plot_prediction_smooth(row)\n",
    "\n",
    "rows = get_curve_models(df_clean,row)\n",
    "\n",
    "rows = rows.iloc[[0,1,2],:]\n",
    "\n",
    "for index, myrow in rows.iterrows():\n",
    "    plot_prediction_smooth(myrow)\n",
    "\n",
    "plt.savefig('power_laws.eps')\n",
    "plt.savefig('power_laws.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b9dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 15193\n",
    "row = df_removed.iloc[num,:]\n",
    "\n",
    "print(num)\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plot_data(row)\n",
    "plot_trn_data(row)\n",
    "plot_prediction_smooth(row)\n",
    "plt.savefig('bad_fit.eps')\n",
    "plt.savefig('bad_fit.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614b7477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44c75bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "row.MSE_tst_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084a8f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 192358\n",
    "row = df_clean.iloc[num,:]\n",
    "\n",
    "print(num)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plot_data(row)\n",
    "plot_trn_data(row)\n",
    "#plot_prediction(row)\n",
    "plot_prediction_smooth(row)\n",
    "plt.ylim([0.45,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc13d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37521dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c51f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 192358\n",
    "row = df_clean.iloc[num,:]\n",
    "\n",
    "rows = get_curve_models(df_clean,row)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plot_data(row)\n",
    "plot_trn_data(row)\n",
    "#plot_prediction(row)\n",
    "for index, myrow in rows.iterrows():\n",
    "    plot_prediction_smooth(myrow)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf6481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 192358\n",
    "row = df_clean.iloc[num,:]\n",
    "\n",
    "rowvap3 = get_curve_model(df_clean,row,'vap3')\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plot_data(row)\n",
    "plot_trn_data(row)\n",
    "plot_prediction_smooth(rowvap3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4de099",
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516e81cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_anchor_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc8812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learner = row.learner\n",
    "openmlid = row.openmlid\n",
    "max_anchor_seen = row.max_anchor_seen\n",
    "\n",
    "df_models = df_clean.query('learner == \"%s\" and openmlid == @openmlid and max_anchor_seen == @max_anchor_seen' % learner)\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db6256",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df_clean['MSE_trn'])\n",
    "plt.ylabel('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f3003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_removed['n'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627ce645",
   "metadata": {},
   "source": [
    "# Distribution of MSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6337b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(series,my_metric,ls='-'):\n",
    "    curbin = 0.0000000005\n",
    "    binlist = [0]\n",
    "    while curbin < 1000000:\n",
    "        binlist.append(curbin)\n",
    "        curbin *= 2\n",
    "    [hist,edges] = np.histogram(series,bins=binlist)\n",
    "    plt.plot(edges[:-1],hist/np.sum(hist),ls,label=my_metric)\n",
    "    plt.xscale('log')\n",
    "\n",
    "plt.figure()    \n",
    "\n",
    "plot_metric(df_total['MSE_trn'],'MSE_trn')\n",
    "plot_metric(df_total['MSE_tst'],'MSE_tst')\n",
    "plot_metric(df_total['MSE_tst_last'],'MSE_tst_last')\n",
    "\n",
    "plt.xlabel('performance bins (logscale)')\n",
    "plt.ylabel('fraction')\n",
    "plt.legend()\n",
    "plt.title('fitting performance distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af888555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_cdf(series,my_metric,ls='-',label=''):\n",
    "    a = series.values\n",
    "    plt.plot(np.sort(a), np.linspace(0, 1, len(a), endpoint=False), ls,label=label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ebde09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4),dpi=100)\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "i = 0\n",
    "for [curve_model, df_curve_model] in df_total.groupby('curve_model'):\n",
    "    ls = '-'\n",
    "    if i > 9:\n",
    "        ls = ':'\n",
    "    plot_metric(df_curve_model['MSE_tst'],curve_model,ls=ls)\n",
    "    #empirical_cdf(df_curve_model['MSE_tst'],curve_model,ls=ls,label=curve_model)\n",
    "    i += 1\n",
    "\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "    \n",
    "plt.xlabel('performance bins (logscale)')\n",
    "plt.ylabel('fraction')\n",
    "plt.legend()\n",
    "plt.title('fitting performance MSE tst')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlim([1e-7,1e1])\n",
    "\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.savefig('distribution_per_learner.png')\n",
    "plt.savefig('distribution_per_learner.eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4a665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4),dpi=100)\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "i = 0\n",
    "for [curve_model, df_curve_model] in df_total.groupby('curve_model'):\n",
    "    ls = '-'\n",
    "    if i > 9:\n",
    "        ls = ':'\n",
    "    #plot_metric(df_curve_model['MSE_tst'],curve_model,ls=ls)\n",
    "    empirical_cdf(df_curve_model['MSE_tst'],curve_model,ls=ls,label=curve_model)\n",
    "    i += 1\n",
    "\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "    \n",
    "plt.xlabel('x (logscale)')\n",
    "plt.ylabel('F(x)')\n",
    "plt.legend()\n",
    "plt.title('Empirical Cumulative Density of MSE tst')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlim([1e-7,1e3])\n",
    "\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56da4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4),dpi=100)\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "i = 0\n",
    "for [n, df_n] in df_total.groupby('fraction'):\n",
    "    ls = '-'\n",
    "    plot_metric(df_n['MSE_tst'],str(n),ls=ls)\n",
    "    i += 1\n",
    "\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "    \n",
    "plt.xlabel('performance bins (logscale)')\n",
    "plt.ylabel('fraction')\n",
    "plt.legend()\n",
    "plt.title('fitting performance MSE tst')\n",
    "\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e42a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['n'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562faacc",
   "metadata": {},
   "source": [
    "# Learning curve of a learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fcd087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure()\n",
    "sns.boxplot(y=\"MSE_tst_last\", data=df_total_clean, palette=\"Set3\") \n",
    "plt.ylim([0,0.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e51fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = 0.25\n",
    "percentage_buckets = [0.05, 0.1, 0.2, 0.4, 1]\n",
    "percentage_buckets = np.array(percentage_buckets)\n",
    "bucket = np.argwhere(percentage < percentage_buckets)[0][0]\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f147f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_total_clean = df_total_clean.query('openmlid == 11')\n",
    "\n",
    "percentage_buckets = [0.05, 0.1, 0.2, 0.4, 1]\n",
    "percentage_buckets = np.array(percentage_buckets)\n",
    "\n",
    "buckets = []\n",
    "\n",
    "for i in range(0,len(df_total_clean)):\n",
    "    row = df_total_clean.iloc[i,:]\n",
    "    percentage = row.percentage\n",
    "    bucket = np.argwhere(percentage < percentage_buckets)[0][0]\n",
    "    buckets.append(bucket)\n",
    "\n",
    "df_total_clean.insert(0,'quartile',buckets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af346f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_clean['quartile'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e079b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = df_total_clean\n",
    "#selected = df_total_clean.query('openmlid == 11')\n",
    "\n",
    "num_datasets = len(selected['openmlid'].unique())\n",
    "\n",
    "fig, axs = plt.subplots(num_datasets,figsize = (8,8*num_datasets))\n",
    "\n",
    "j = 0\n",
    "for openmlid, df_dataset in selected.groupby(\"openmlid\"):\n",
    "    i = 0\n",
    "    ls = '-'\n",
    "    for curve_model, df_curve_model in df_dataset.groupby(\"curve_model\"):\n",
    "\n",
    "        Y = df_curve_model.groupby('percentage')['MSE_tst_last'].median()\n",
    "        Y_sigma = df_curve_model.groupby('percentage')['MSE_tst_last'].std()\n",
    "        X = df_curve_model.groupby('percentage')['MSE_tst_last'].median().index\n",
    "        if i > 9:\n",
    "            ls = ':'\n",
    "        if num_datasets > 1:\n",
    "            my_ax = axs[j]\n",
    "        else:\n",
    "            my_ax = axs\n",
    "        my_ax.plot(X,Y,ls,label=curve_model)\n",
    "        \n",
    "        i += 1\n",
    "    my_ax.set_ylim([0,0.002])\n",
    "    my_ax.set_title('openmlid %d' % openmlid)\n",
    "    j += 1\n",
    "    \n",
    "plt.xlabel('percentage of anchors used')\n",
    "plt.ylabel('median MSE on last anchor')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e017fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = df_total_clean\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "ls = '-'\n",
    "i = 0\n",
    "for curve_model, df_curve_model in selected.groupby(\"curve_model\"):\n",
    "\n",
    "    Y = df_curve_model.groupby('quartile')['MSE_tst_last'].median()\n",
    "    Y_sigma = df_curve_model.groupby('quartile')['MSE_tst_last'].std()\n",
    "    X = df_curve_model.groupby('quartile')['MSE_tst_last'].median().index\n",
    "\n",
    "    if i > 9:\n",
    "        ls = ':'\n",
    "    i += 1\n",
    "    plt.plot(X,Y,ls,label=curve_model)\n",
    "    \n",
    "plt.xlabel('# anchors used')\n",
    "plt.ylabel('median MSE')\n",
    "plt.legend()\n",
    "plt.ylim([0,0.003])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dada7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.boxplot(x=\"quartile\", y=\"MSE_tst_last\", data=df_total_clean, palette=\"Set3\") \n",
    "plt.ylim([0,0.4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48832e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_buckets_str = ['curve_model']\n",
    "for perc in percentage_buckets:\n",
    "    percentage_buckets_str.append(str(perc))\n",
    "percentage_buckets_str = percentage_buckets_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f39c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5b0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b776d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_buckets_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d0d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c325146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for curve_model, df_subgroup in df_total_clean.groupby([\"curve_model\"]):\n",
    "    row = [curve_model]\n",
    "    for quartile, df_subgroup2 in df_subgroup.groupby(['quartile']):\n",
    "        row.append(df_subgroup2['MSE_tst_last'].median())\n",
    "    rows.append(row)\n",
    "    \n",
    "my_res = pd.DataFrame(rows,columns=[percentage_buckets_str])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87356bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4276b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_res_ranks = my_res.copy()\n",
    "for col in percentage_buckets_str:\n",
    "    if col == 'curve_model':\n",
    "        continue\n",
    "    my_res_ranks[col] = my_res_ranks[col].rank(method='average')\n",
    "my_res_ranks['0.05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8496f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\\\begin{table}[]')\n",
    "print('\\\\ttfamily')\n",
    "print('\\\\begin{tabular}{lllll}')\n",
    "for (i,text) in enumerate(percentage_buckets_str):\n",
    "    if text == 'curve_model':\n",
    "        text = 'curve model'\n",
    "    if i == 0:\n",
    "        print('%12s' % text,' ',end='')\n",
    "    else:\n",
    "        print('%8s' % text,' ',end='')\n",
    "    if i < 4:\n",
    "        print('&',end='')\n",
    "print('\\\\\\\\')\n",
    "first = True\n",
    "for i in range(0,len(my_res)):\n",
    "    row = my_res.iloc[i,:]\n",
    "    for (j,num) in enumerate(row.values):\n",
    "        if j == 0:\n",
    "            if num == 'baseline_last_constant':\n",
    "                num = 'last1'\n",
    "            print('%12s' % num,' ',end='')\n",
    "        else:\n",
    "            rank = my_res_ranks.iloc[i,j]\n",
    "            if rank >= 1 and rank <= 3.5: # [1,2,3]:\n",
    "                print('\\\\cellcolor{YellowGreen}{%8.5f} '%num,end='')\n",
    "            elif rank > 3.5 and rank <= 7.5: # in [4, 5, 6, 7]:\n",
    "                print('\\\\cellcolor{Goldenrod}{%8.5f} '%num,end='')\n",
    "            elif rank > 7.5 and rank <= 10.5: #rank in [8, 9, 10]:\n",
    "                print('\\\\cellcolor{White}{%8.5f} '%num,end='')\n",
    "            elif rank > 10.5 and rank <= 14: # rank in [12,13,14]:\n",
    "                print('\\\\cellcolor{Gray}{%8.5f} '%num,end='')\n",
    "            else:\n",
    "                print('\\\\cellcolor{Red}{%8.5f} '%num,end='')\n",
    "                #print(' ')\n",
    "                #print(rank)\n",
    "                #print(' ')\n",
    "        if j < 4:\n",
    "            print('&',end='')\n",
    "    print('\\\\\\\\')\n",
    "print('\\\\end{tabular}')\n",
    "print('\\\\end{table}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d485ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_total_clean.groupby('curve_model')['MSE_tst_last'].median()\n",
    "a.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ecee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_clean['learner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99c22db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_clean.groupby('learner')['MSE_tst_last'].median().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33cacb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb87ade",
   "metadata": {},
   "source": [
    "# Look at parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7e28cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539c8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "beta_str = beta[0]\n",
    "beta_str = beta_str[1:-1]\n",
    "beta_parts = beta_str.split(' ')\n",
    "myfloat = []\n",
    "for part in beta_parts:\n",
    "    part = part.replace(',','')\n",
    "    part = part.replace('\\n','')\n",
    "    myfloat.append(float(part))\n",
    "myfloat = tuple(myfloat)\n",
    "return myfloat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad593296",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_curve_models = df_total_clean['curve_model'].unique()\n",
    "num_curve_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b5db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "row.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb36be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d10918",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df47dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "j = 0\n",
    "df_selected = df_total_clean.query('curve_model == \"lin2\"')\n",
    "for curve_model, df_dataset in df_selected.groupby(\"curve_model\"):\n",
    "    beta_list = []\n",
    "    for i in range(0,len(df_dataset)):\n",
    "        row = df_dataset.iloc[i,:]\n",
    "        beta = parse_beta([row.beta])\n",
    "        beta2 = list(beta)\n",
    "        beta_list.append(beta2)\n",
    "\n",
    "#    a = np.array(beta_list)\n",
    "#    plt.boxplot(a)\n",
    "#    plt.ylim([-0.25,0.25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d6c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for [i, beta] in enumerate(beta_list):\n",
    "    if not len(beta) == 2:\n",
    "        print(i,beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4534da",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_list = []\n",
    "i = 0\n",
    "row = df_dataset.iloc[i,:]\n",
    "beta = parse_beta([row.beta])\n",
    "beta2 = list(beta)\n",
    "beta_list.append(beta2)\n",
    "i = 1\n",
    "row = df_dataset.iloc[i,:]\n",
    "beta = parse_beta([row.beta])\n",
    "beta2 = list(beta)\n",
    "beta_list.append(beta2)\n",
    "i = 2\n",
    "row = df_dataset.iloc[i,:]\n",
    "beta = parse_beta([row.beta])\n",
    "beta2 = list(beta)\n",
    "beta_list.append(beta2)\n",
    "beta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19896bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_clean\n",
    "\n",
    "#df_selected = df_total_clean.query('curve_model == \"lin2\" and MSE_trn < 0.05')\n",
    "#df_selected = df_total_clean.query('curve_model == \"lin2\"')\n",
    "df_selected = df_total_clean\n",
    "\n",
    "fig, axs = plt.subplots(len(num_curve_models),figsize=(15,15))\n",
    "j = 0\n",
    "for curve_model, df_dataset in df_selected.groupby(\"curve_model\"):\n",
    "    beta_list = []\n",
    "    for i in range(0,len(df_dataset)):\n",
    "        row = df_dataset.iloc[i,:]\n",
    "        beta = parse_beta([row.beta])\n",
    "        beta_list.append(beta)\n",
    "\n",
    "    a = np.array(beta_list)\n",
    "    axs[j].boxplot(a)\n",
    "    axs[j].set_ylim([-2,2])\n",
    "    axs[j].set_title(curve_model)\n",
    "    j = j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2838e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(beta_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a55cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_list = np.empty((1,1))\n",
    "total_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f35dcdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43b82cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_clean\n",
    "\n",
    "#df_selected = df_total_clean.query('curve_model == \"lin2\" and MSE_trn < 0.05')\n",
    "#df_selected = df_total_clean.query('curve_model == \"lin2\"')\n",
    "df_selected = df_total_clean\n",
    "\n",
    "first = True\n",
    "for curve_model, df_dataset in df_selected.groupby(\"curve_model\"):\n",
    "    beta_list = []\n",
    "    for i in range(0,len(df_dataset)):\n",
    "        row = df_dataset.iloc[i,:]\n",
    "        beta = row.beta\n",
    "        beta_list.append(beta)\n",
    "    beta_list = np.array(beta_list)\n",
    "    if first:\n",
    "        total_list = np.reshape(beta_list,(-1,1))\n",
    "        first = False\n",
    "    else:\n",
    "        total_list = np.hstack((total_list,beta_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84069cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(total_list).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa346476",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c6300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "791fd340",
   "metadata": {},
   "source": [
    "# Visualize fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc651c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3484b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf98d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learners = df['learner'].unique()\n",
    "learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dd518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learner = learners[18]\n",
    "openmlid = 11\n",
    "n = 9\n",
    "df_selected = df_total_clean.query('openmlid==@openmlid and learner==@learner and n==@n')\n",
    "df_selected\n",
    "\n",
    "[X, Y] = get_info_mean_curve(df_anchors_and_scores, openmlid, learner)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(X,Y,'*')\n",
    "for i in range(0,len(df_selected)):\n",
    "    row = df_selected.iloc[i,:]\n",
    "    Y_hat = row.prediction\n",
    "    plt.plot(X,Y_hat,'-',label=row.curve_model)\n",
    "    \n",
    "plt.title('%s dataset %d' % (learner, openmlid))\n",
    "plt.ylim([np.min(Y),np.max(Y)])\n",
    "plt.xlabel('train samples')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea732c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = 'sklearn.linear_model.Perceptron'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2e409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    def exp3(beta):\n",
    "#        a, b, c = tuple(beta.astype(float))\n",
    "#        pl = lambda x: a * np.exp(-b*x) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a080fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pow4(sizes, scores):\n",
    "    def pow4(beta):\n",
    "        a, b, c, d = tuple(beta.astype(float))\n",
    "        pl = lambda x: c - (-a*x + b)**d\n",
    "        penalty = []\n",
    "        for i, size in enumerate(sizes):\n",
    "            penalty.append((pl(size) - scores[i])**2)\n",
    "        return np.array(penalty)\n",
    "\n",
    "    a, b, c, d = tuple(sp.optimize.least_squares(pow4, np.array([0.0001,0.2,1,1]), method=\"lm\").x)\n",
    "    return (a, b, c, d), lambda x: c - (-a*x + b)**d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36060b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[beta,func] = get_exp2_good_init(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b116161",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8977f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = learners[0]\n",
    "openmlid = 11\n",
    "\n",
    "[X, Y] = get_info_mean_curve(df_anchors_and_scores, openmlid, learner)\n",
    "\n",
    "beta, pow4 = get_pow4(X,Y)\n",
    "\n",
    "Y_hat = pow4(X)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(X,Y,'*')\n",
    "plt.plot(X, Y_hat, '-o')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ce267",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b264fd24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d1f5bcd",
   "metadata": {},
   "source": [
    "# Learner influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d0edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b75a010",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_clean.boxplot(column='MSE_tst_last',by='learner',rot=90)\n",
    "plt.ylim([0,0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9106da",
   "metadata": {},
   "source": [
    "# Curve model influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40f2912",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_clean.boxplot(column='MSE_tst_last',by='curve_model',rot=90)\n",
    "plt.ylim([0,0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ca64a6",
   "metadata": {},
   "source": [
    "# Compute Jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d90150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy.utilities.lambdify import lambdify\n",
    "import sympy as sym\n",
    "\n",
    "def get_fun_sym(model_id):\n",
    "    \n",
    "    x = sym.Symbol('x')\n",
    "    y = sym.Symbol('y')\n",
    "    a = sym.Symbol('a')\n",
    "    b = sym.Symbol('b')\n",
    "    c = sym.Symbol('c')\n",
    "    d = sym.Symbol('d')\n",
    "    \n",
    "    if model_id == 'pow2':\n",
    "        fun = sym.Matrix([-a * x **(-b)])\n",
    "        fun = -a * x **(-b)\n",
    "        #J = np.array([-X**(-b), a*X**(-b)*np.log(X)])\n",
    "    if model_id == 'pow3':\n",
    "        fun = sym.Matrix([a - b * x **(-c)])\n",
    "        fun = a - b * x **(-c)\n",
    "        #J = np.array([np.ones_like(X), -X**(-c), b*X**(-c)*np.log(X)])\n",
    "    if model_id == 'log2':\n",
    "        fun = sym.Matrix([-a * sym.log(x) + b])\n",
    "        fun = -a * sym.log(x) + b\n",
    "        #J = np.array([-np.log(X), np.ones_like(X)])\n",
    "    if model_id == 'exp3':\n",
    "        fun = sym.Matrix([a * sym.exp(-b*x) + c])\n",
    "        fun = a * sym.exp(-b*x) + c\n",
    "        #J = np.array([exp(-b*X), -a*X*np.exp(-b*X), np.ones_like(X)])\n",
    "    if model_id == 'exp2':\n",
    "        fun = sym.Matrix([a * sym.exp(-b*x)])\n",
    "        fun = a * sym.exp(-b*x)\n",
    "        #J = np.array([exp(-b*X), -a*X*exp(-b*X)])\n",
    "    if model_id == 'lin2':\n",
    "        fun = sym.Matrix([a * x + b])\n",
    "        fun = a * x + b\n",
    "        #J = np.array([X, np.ones_like(X)])\n",
    "    if model_id == 'vap3':\n",
    "        fun = sym.Matrix([sym.exp(a + b/x + c * sym.log(x))])\n",
    "        fun = sym.exp(a + b/x + c * sym.log(x))\n",
    "        #J = np.array([np.exp(a + b/X + c*np.log(X)), np.exp(a + b/X + c*log(X))/X, np.exp(a + b/X + c*np.log(X))*np.log(X)])\n",
    "    if model_id == 'mmf4':\n",
    "        fun = sym.Matrix([(a * b + c * x ** d)/(b + x ** d)])\n",
    "        fun = (a * b + c * x ** d)/(b + x ** d)\n",
    "        #J = np.array([b/(b + X**d), a/(b + X**d) - (a*b + c*X**d)/(b + X**d)**2, X**d/(b + X**d), c*X**d*np.log(X)/(b + X**d) - X**d*(a*b + c*X**d)*np.log(X)/(b + X**d)**2])\n",
    "    if model_id == 'wbl4':\n",
    "        fun = sym.Matrix([(c - b * sym.exp(-a*(x**d)))])\n",
    "        fun = (c - b * sym.exp(-a*(x**d)))\n",
    "        #J = np.array([b*X**d*np.exp(-a*X**d), -np.exp(-a*X**d), np.ones_like(X), a*b*X**d*np.exp(-a*X**d)*np.log(X)])\n",
    "    if model_id == 'exp4':\n",
    "        fun = sym.Matrix([c - sym.exp(-a*(x**d) + b)])\n",
    "        fun = c - sym.exp(-a*(x**d) + b)\n",
    "        #J = np.array([X**d*np.exp(-a*X**d + b), -np.exp(-a*X**d + b), np.ones_like(X), a*X**d*np.exp(-a*X**d + b)*np.log(X)])\n",
    "    if model_id == 'expp3':\n",
    "        fun = sym.Matrix([c - sym.exp((x-b)**a)])\n",
    "        fun = c - sym.exp((x-b)**a)\n",
    "        #J = np.array([-(-b + X)**a*np.exp((-b + X)**a)*np.log(-b + X), a*(-b + X)**a*np.exp((-b + X)**a)/(-b + X), np.ones_like(X)])\n",
    "    if model_id == 'pow4':\n",
    "        fun = sym.Matrix([a - b*(x + d)**(-c)]) # has to closely match pow3\n",
    "        fun = a - b*(x + d)**(-c)\n",
    "        #J = np.array([np.ones_like(X), -(d + X)**(-c), b*(d + X)**(-c)*np.log(d + X), b*c*(d + X)**(-c)/(d + X)])\n",
    "    if model_id == 'ilog2':\n",
    "        fun = sym.Matrix([b - (a/sym.log(x))])\n",
    "        fun = b - (a/sym.log(x))\n",
    "        #J = np.array([-1/log(X), np.ones_like(X)])\n",
    "    if model_id == 'expd3':\n",
    "        fun = sym.Matrix([c - (c - a)*sym.exp(-b*x)])\n",
    "        fun = c - (c - a)*sym.exp(-b*x)\n",
    "        #J = np.array([np.exp(-b*X), -X*(a - c)*np.exp(-b*X), np.ones_like(X) - np.exp(-b*X)])\n",
    "    if model_id == 'logpower3':\n",
    "        fun = sym.Matrix([a / (1 + (x / sym.exp(b))**c)])\n",
    "        fun = a / (1 + (x / sym.exp(b))**c)\n",
    "        #J1 = ((X*np.exp(-b))**c + np.ones_like(X))**(-1.0)\n",
    "        #J2 = a*c*(X*np.exp(-b))**c/((X*np.exp(-b))**c + np.ones_like(X))**2\n",
    "        #J3 = -a*(X*np.exp(-b))**c*np.log(X*np.exp(-b))/((X*np.exp(-b))**c + np.ones_like(X))**2\n",
    "        #J = np.array([J1, J2, J3])\n",
    "    if model_id == 'last1':\n",
    "        fun = a\n",
    "    return fun\n",
    "\n",
    "model_id = 'logpower3'\n",
    "#fun = get_fun_sym(model_id)\n",
    "#num_par = get_num_par(model_id)\n",
    "#if num_par == 2:\n",
    "#    beta = sym.Matrix([a,b])\n",
    "#if num_par == 3:\n",
    "#    beta = sym.Matrix([a,b,c])\n",
    "#if num_par == 4:\n",
    "#    beta = sym.Matrix([a,b,c,d])\n",
    "    \n",
    "#J = fun.jacobian(beta)\n",
    "#if num_par == 2:\n",
    "#    fastJ = lambdify(['a','b','x'],J)\n",
    "#    fastJ2 = lambda beta, x: fastJ(beta[0],beta[1],x)\n",
    "#if num_par == 3:\n",
    "#    fastJ = lambdify(['a','b','c','x'],J)\n",
    "#    fastJ2 = lambda beta, x: fastJ(beta[0],beta[1],beta[2],x)\n",
    "#if num_par == 4:\n",
    "#    fastJ = lambdify(['a','b','c','d','x'],J)\n",
    "#    fastJ2 = lambda beta, x: fastJ(beta[0],beta[1],beta[2],beta[3],x)\n",
    "#\n",
    "#inspect.getsource(fastJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbe11dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83789047",
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = a\n",
    "fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c5692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2094aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71180ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import latex\n",
    "\n",
    "for cm in cm_ordered:\n",
    "    fun = get_fun_sym(cm)\n",
    "    print(cm, end=' & ')\n",
    "    print('$%s$' % latex(fun), end=' & ')\n",
    "    print(ref[cm],end=' \\\\\\\\\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec500d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy.utilities.lambdify import lambdify\n",
    "inspect.getsource(fastJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cbb42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "compare = c[['pow2','pow4']]\n",
    "# filter nans and infs\n",
    "ind_nan_or_inf = compare.isin([np.inf, -np.inf, np.nan]).any(axis=1)\n",
    "c = compare[ind_nan_or_inf == False]\n",
    "ttest_ind(c.iloc[:,0],c.iloc[:,1], equal_var=False, nan_policy='propagate', alternative='two-sided')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = c['pow3']\n",
    "mean = np.mean(dat)\n",
    "std = np.std(dat)\n",
    "pg.qqplot(dat, dist='norm', sparams=(mean, std))\n",
    "plt.ylim([-5,5])\n",
    "plt.xlim([-5,5])\n",
    "\n",
    "a = np.array(rows)\n",
    "a = np.log(a)\n",
    "a = pd.DataFrame(a,columns=curve_models)\n",
    "a_info = np.array(info_rows)\n",
    "a_info = pd.DataFrame(a_info,columns=['openmlid','learner','n'])\n",
    "b = pd.concat([a_info,a],axis=1)\n",
    "b\n",
    "\n",
    "\n",
    "\n",
    "aov = pg.rm_anova(dv='value', within='variable', subject='condition', data=melted, detailed=False)\n",
    "aov\n",
    "\n",
    "rep = pg.pairwise_ttests(data=melted, dv='value', within='variable', subject='condition',nan_policy='pairwise',padjust='bonf')\n",
    "\n",
    "#pingouin.pairwise_ttests(data=None, dv=None, between=None, within=None, subject=None, parametric=True, marginal=True, alpha=0.05, alternative='two-sided', padjust='none', effsize='hedges', correction='auto', nan_policy='listwise', return_desc=False, interaction=True, within_first=True)\n",
    "rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d945d318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "p_values_tom = []\n",
    "for i in range(0,len(rep)):\n",
    "    row = rep.iloc[i,:]\n",
    "    p = row['p-corr']\n",
    "    if p < 0.05:\n",
    "        sig = True\n",
    "    else:\n",
    "        sig = False\n",
    "    p_values_tom.append((row.A,row.B,p,sig))\n",
    "p_values_tom.sort(key=operator.itemgetter(2))\n",
    "p_values_tom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3c6f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c = remove_rows_with_nan_or_inf(b[curve_models])\n",
    "print('*' * 50)\n",
    "print(pg.homoscedasticity(c))\n",
    "print('*' * 50)\n",
    "print(pg.normality(c))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5842cb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.statology.org/repeated-measures-anova-python/\n",
    "# do repeated anova,\n",
    "# drug\n",
    "# print(AnovaRM(data=df, depvar='response', subject='patient', within=['drug']).fit())\n",
    "# response = MSE\n",
    "# subject = setting (openmlid,learner,n)\n",
    "# within = curve_model \n",
    "\n",
    "import pingouin as pg\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
